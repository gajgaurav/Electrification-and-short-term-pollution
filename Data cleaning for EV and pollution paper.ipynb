{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a7f2482",
   "metadata": {},
   "source": [
    "In this code file, we use the following files/directories to create the variables used for our regressions:\n",
    "1. All RTO dataframes (2010-23), a directory which contains excel files of monthy RTO level data for more than 1200 RTOs for the time period Jan 2010 - Dec 2023 (link: https://vahan.parivahan.gov.in/vahan4dashboard/vahan/view/reportview.xhtml).\n",
    "\n",
    "2. Updated arcGIS RTO to district matching.xlsx, an excel file which contains the mapping of RTOs to their present districts (link: https://www.arcgis.com/home/item.html?id=79875d04f49241979bed4b7a8e5bfdd8#data). In cases where the website does not contain a particular RTO to district mapping, I map these manually.\n",
    "\n",
    "3. final_mapping.csv, a csv file which maps the arcGIS reported districts to their 2011 counterparts. This is done for consistency purposes and is also done manually. In cases where current districts come from multiple 2011 districts, they will be mapped to the group of districts\n",
    "\n",
    "4. 2011 districts datameet boundaries.zip, a directory which contains a shapefile of the boundaries for districts according to the 2011 census (link: https://projects.datameet.org/maps/districts/). Based on final_mapping.csv, I create new district boundaries (including for group of districts) in latest grouped district boundaries.shp.\n",
    "\n",
    "5. correct district naming.xlsx, an excel file which contains the names of 2011 districts as present in government documents. Again, done for consistency purposes and in case demographic data is to be incorporated later.\n",
    "\n",
    "6. weather data, a directory which contains excel files of multiple weather readings for coordinates across India.\n",
    "\n",
    "7. India urbanness shapefile Columbia.zip, a file which contains the boundaries of areas on their urbanness classification, based on 2011 factors. Urbanness is defined according to GHSL (link: https://sedac.ciesin.columbia.edu/data/set/india-spatial-india-census-2011/data-download).\n",
    "\n",
    "8. higher resolution PM2.5 data monthly files, a directory containing netCDF files with monthly PM2.5 data at coordinates across India (link: https://sites.wustl.edu/acag/datasets/surface-pm2-5/). We use version V5.GL.01.\n",
    "\n",
    "9. Monthly nightlight data (all years), a directory containing satellite images of VIIRS nightlight data across the world. This is at a monthly frequency (link: https://eogdata.mines.edu/nighttime_light/monthly/v10/). Available for April 2012 onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384552b",
   "metadata": {},
   "source": [
    "As we progress, one thing to keep in mind is the datetime format in python. Let's say a row corresponds to November, 2023. To save it in a datetime object format, it gets saved as 2023-11-01 by default. This does not mean however that the row was recorded on November 1, 2023. In the final section, when we are merging our datasets, we will be dealing with aggregates (total registrations, average PM2.5, average urban nightlight, etc.) and even though the row would mention the date YYYY-MM-01, it wouldn't mean it's for the first day but instead for the entire month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db0e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "import zipfile as zf\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from netCDF4 import Dataset\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from netCDF4 import Dataset\n",
    "from rasterio.enums import Resampling\n",
    "import rioxarray as rxr\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766c780",
   "metadata": {},
   "source": [
    "# Section 1: Mapping vehicle registration data to 2011 districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2835664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING A FUNCTION TO EXTRACT RELEVANT VARIABLES FROM THE TABULAR FORMAT OF THE EXCEL FILES\n",
    "def table_to_data(table):\n",
    "    \n",
    "    info = table.columns[0]\n",
    "    \n",
    "    # TAKING TAIL(-2) EXCLUDES THE TOP 2 NULL VALUES ROWS\n",
    "    table = table.tail(-2)\n",
    "\n",
    "    # CHANGING THE NAME OF THE COLUMN HEAD TO MAKE IT EASIER FOR NAME MANIPULATION LATER ON\n",
    "    table.iloc[0][1] = table.columns[1]\n",
    "    table.iloc[0][-1] = table.columns[-1]\n",
    "\n",
    "    # REPLACING THE COLUMN NAMES\n",
    "    table.columns = table.iloc[0] \n",
    "    table.iloc[0][-1] = table.columns[-1]\n",
    "\n",
    "    table = table.rename(columns = {table.columns[0] : 'serial',\n",
    "                                    table.columns[1] : 'fuel',\n",
    "                                    table.columns[-1] : 'total'})\n",
    "    \n",
    "    table = table.drop(columns = ['serial', 'total'])\n",
    "\n",
    "    # GETTING RID OF THE USELESS FIRST ROW\n",
    "    table = table.reset_index(drop = True).loc[1:]\n",
    "\n",
    "    # CONVERTS INTO A LONG FORMAT\n",
    "    table = pd.melt(table, id_vars = ['fuel'], var_name = 'month', value_name = 'count')\n",
    "    table['info'] = info\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad32ae58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fuel Month Wise Data  of CHARAIDEO - AS33 , Assam (2011)</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S No</td>\n",
       "      <td>Fuel</td>\n",
       "      <td>Month Wise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOTAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JAN</td>\n",
       "      <td>FEB</td>\n",
       "      <td>MAR</td>\n",
       "      <td>APR</td>\n",
       "      <td>MAY</td>\n",
       "      <td>JUN</td>\n",
       "      <td>JUL</td>\n",
       "      <td>AUG</td>\n",
       "      <td>SEP</td>\n",
       "      <td>OCT</td>\n",
       "      <td>NOV</td>\n",
       "      <td>DEC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>DIESEL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>PETROL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Fuel Month Wise Data  of CHARAIDEO - AS33 , Assam (2011)  \\\n",
       "0                                               S No         \n",
       "1                                                NaN         \n",
       "2                                                NaN         \n",
       "3                                                  1         \n",
       "4                                                  2         \n",
       "\n",
       "                                          Unnamed: 1   Unnamed: 2 Unnamed: 3  \\\n",
       "0                        Fuel                         Month Wise         NaN   \n",
       "1                                                NaN          NaN        NaN   \n",
       "2                                                NaN          JAN        FEB   \n",
       "3                                             DIESEL            0          0   \n",
       "4                                             PETROL            0          0   \n",
       "\n",
       "  Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2        MAR        APR        MAY        JUN        JUL        AUG   \n",
       "3          1          0          0          1          0          0   \n",
       "4          0          0          0          0          1          0   \n",
       "\n",
       "  Unnamed: 10 Unnamed: 11 Unnamed: 12 Unnamed: 13      Unnamed: 14  \n",
       "0         NaN         NaN         NaN         NaN       TOTAL       \n",
       "1         NaN         NaN         NaN         NaN              NaN  \n",
       "2         SEP         OCT         NOV         DEC              NaN  \n",
       "3           0           0           0           0                2  \n",
       "4           0           0           0           0                1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registration_files = zf.ZipFile(\"All RTO dataframes (2010-23).zip\", 'r')\n",
    "registration_files.extractall('Vehicle registration files')\n",
    "\n",
    "files_list = os.listdir('Vehicle registration files/All RTO dataframes (2010-23)')\n",
    "example_table = pd.read_excel('Vehicle registration files/All RTO dataframes (2010-23)/' + files_list[0])\n",
    "example_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41e776ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuel</th>\n",
       "      <th>month</th>\n",
       "      <th>count</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>JAN</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>JAN</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>FEB</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>FEB</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>MAR</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>MAR</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>APR</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>APR</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>MAY</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>MAY</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>JUN</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>JUN</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>JUL</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>JUL</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>AUG</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>AUG</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>SEP</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>SEP</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>OCT</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>OCT</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>NOV</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>NOV</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>DEC</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>DEC</td>\n",
       "      <td>0</td>\n",
       "      <td>Fuel Month Wise Data  of CHARAIDEO - AS33 , As...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fuel month count                                               info\n",
       "0   DIESEL   JAN     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "1   PETROL   JAN     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "2   DIESEL   FEB     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "3   PETROL   FEB     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "4   DIESEL   MAR     1  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "5   PETROL   MAR     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "6   DIESEL   APR     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "7   PETROL   APR     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "8   DIESEL   MAY     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "9   PETROL   MAY     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "10  DIESEL   JUN     1  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "11  PETROL   JUN     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "12  DIESEL   JUL     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "13  PETROL   JUL     1  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "14  DIESEL   AUG     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "15  PETROL   AUG     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "16  DIESEL   SEP     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "17  PETROL   SEP     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "18  DIESEL   OCT     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "19  PETROL   OCT     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "20  DIESEL   NOV     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "21  PETROL   NOV     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "22  DIESEL   DEC     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As...\n",
       "23  PETROL   DEC     0  Fuel Month Wise Data  of CHARAIDEO - AS33 , As..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_to_data(example_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "552f02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLYING THE table_to_data FUNCTION TO EACH OF THE 17000 OR SO EXCEL FILES AND ADDING THEM ALL TO A LIST CALLED\n",
    "# tables_list\n",
    "\n",
    "files_list = os.listdir('Vehicle registration files/All RTO dataframes (2010-23)')\n",
    "tables_list = []\n",
    "\n",
    "for file_number in range(0,len(files_list)):\n",
    "    if '__MACOSX' in files_list[file_number]:\n",
    "        pass\n",
    "    elif '.ipynb_checkpoints' in files_list[file_number]:\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        current_table = pd.read_excel('Vehicle registration files/All RTO dataframes (2010-23)/' + files_list[file_number])\n",
    "        current_table = table_to_data(current_table)\n",
    "        \n",
    "        tables_list.append(current_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9e4ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERTICALLY APPENDING ALL THE TABLES FROM tables_list INTO ONE MAIN DATAFRAME CALLED main_df\n",
    "\n",
    "main_df = pd.concat(tables_list, axis = 0).reset_index(drop = True)\n",
    "main_df = main_df.drop_duplicates()\n",
    "\n",
    "# CREATING ROWS FOR OTHER RELEVANT VARIABLES USING THE info COLUMN\n",
    "\n",
    "# COLUMNS TO SEPERATE OUT THE INFORMATION \n",
    "\n",
    "main_df['state_year'] = main_df['info'].apply(lambda x: x.split('Fuel Month Wise Data  of')[1].split(',')[-1].strip())\n",
    "main_df['year'] = main_df['info'].apply(lambda x: x.split('(')[-1][:-1].strip())\n",
    "main_df['state'] = main_df['state_year'].apply(lambda x: x.split('(')[0].strip())\n",
    "main_df['rto'] = main_df['info'].apply(lambda x: ''.join(x.split(',')[:-1]).split('Fuel Month Wise Data  of')[1].strip())\n",
    "main_df['rto_code'] = main_df['rto'].apply(lambda x: x.split('-')[-1].strip())\n",
    "main_df['rto_name'] = main_df['rto'].apply(lambda x: ' '.join(x.split('-')[:-1]).strip())\n",
    "main_df['state_symbol'] = main_df['rto_code'].str.extract('([a-zA-Z]+)')\n",
    "main_df = main_df.drop(columns = ['info', 'state_year'])\n",
    "\n",
    "# AP126 DOES NOT HAVE VALUES FOR 2023 AND THEREFORE WE SKIP OUT THIS RTO FROM FURTHER ANALYSIS\n",
    "\n",
    "main_df = main_df[main_df['rto_code'] != 'AP126']\n",
    "\n",
    "# CONVERTING TO INTEGER VALUES FOR CALCULATION\n",
    "\n",
    "main_df['count'] = main_df['count'].apply(lambda x: x.replace(',', ''))\n",
    "main_df['count'] = main_df['count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4de0eb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuel</th>\n",
       "      <th>month</th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>rto</th>\n",
       "      <th>rto_code</th>\n",
       "      <th>rto_name</th>\n",
       "      <th>state_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>JAN</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Assam</td>\n",
       "      <td>CHARAIDEO - AS33</td>\n",
       "      <td>AS33</td>\n",
       "      <td>CHARAIDEO</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>JAN</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Assam</td>\n",
       "      <td>CHARAIDEO - AS33</td>\n",
       "      <td>AS33</td>\n",
       "      <td>CHARAIDEO</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>FEB</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Assam</td>\n",
       "      <td>CHARAIDEO - AS33</td>\n",
       "      <td>AS33</td>\n",
       "      <td>CHARAIDEO</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>FEB</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Assam</td>\n",
       "      <td>CHARAIDEO - AS33</td>\n",
       "      <td>AS33</td>\n",
       "      <td>CHARAIDEO</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>MAR</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Assam</td>\n",
       "      <td>CHARAIDEO - AS33</td>\n",
       "      <td>AS33</td>\n",
       "      <td>CHARAIDEO</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171507</th>\n",
       "      <td>PETROL/HYBRID</td>\n",
       "      <td>NOV</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>MAJITHA SDM - PB81</td>\n",
       "      <td>PB81</td>\n",
       "      <td>MAJITHA SDM</td>\n",
       "      <td>PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171508</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>DEC</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>MAJITHA SDM - PB81</td>\n",
       "      <td>PB81</td>\n",
       "      <td>MAJITHA SDM</td>\n",
       "      <td>PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171509</th>\n",
       "      <td>DIESEL/HYBRID</td>\n",
       "      <td>DEC</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>MAJITHA SDM - PB81</td>\n",
       "      <td>PB81</td>\n",
       "      <td>MAJITHA SDM</td>\n",
       "      <td>PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171510</th>\n",
       "      <td>PETROL</td>\n",
       "      <td>DEC</td>\n",
       "      <td>69</td>\n",
       "      <td>2019</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>MAJITHA SDM - PB81</td>\n",
       "      <td>PB81</td>\n",
       "      <td>MAJITHA SDM</td>\n",
       "      <td>PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171511</th>\n",
       "      <td>PETROL/HYBRID</td>\n",
       "      <td>DEC</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>MAJITHA SDM - PB81</td>\n",
       "      <td>PB81</td>\n",
       "      <td>MAJITHA SDM</td>\n",
       "      <td>PB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1166976 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fuel month  count  year   state                 rto  \\\n",
       "0               DIESEL   JAN      0  2011   Assam    CHARAIDEO - AS33   \n",
       "1               PETROL   JAN      0  2011   Assam    CHARAIDEO - AS33   \n",
       "2               DIESEL   FEB      0  2011   Assam    CHARAIDEO - AS33   \n",
       "3               PETROL   FEB      0  2011   Assam    CHARAIDEO - AS33   \n",
       "4               DIESEL   MAR      1  2011   Assam    CHARAIDEO - AS33   \n",
       "...                ...   ...    ...   ...     ...                 ...   \n",
       "1171507  PETROL/HYBRID   NOV      0  2019  Punjab  MAJITHA SDM - PB81   \n",
       "1171508         DIESEL   DEC      5  2019  Punjab  MAJITHA SDM - PB81   \n",
       "1171509  DIESEL/HYBRID   DEC      0  2019  Punjab  MAJITHA SDM - PB81   \n",
       "1171510         PETROL   DEC     69  2019  Punjab  MAJITHA SDM - PB81   \n",
       "1171511  PETROL/HYBRID   DEC      1  2019  Punjab  MAJITHA SDM - PB81   \n",
       "\n",
       "        rto_code     rto_name state_symbol  \n",
       "0           AS33    CHARAIDEO           AS  \n",
       "1           AS33    CHARAIDEO           AS  \n",
       "2           AS33    CHARAIDEO           AS  \n",
       "3           AS33    CHARAIDEO           AS  \n",
       "4           AS33    CHARAIDEO           AS  \n",
       "...          ...          ...          ...  \n",
       "1171507     PB81  MAJITHA SDM           PB  \n",
       "1171508     PB81  MAJITHA SDM           PB  \n",
       "1171509     PB81  MAJITHA SDM           PB  \n",
       "1171510     PB81  MAJITHA SDM           PB  \n",
       "1171511     PB81  MAJITHA SDM           PB  \n",
       "\n",
       "[1166976 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0afaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING 2 SEPERATE DATAFRAMES TO COUNT TOTAL MONTHLY REGISTRATIONS AT THE RTO LEVEL AND MONTHLY EV REGISTRATIONS\n",
    "# AT THE RTO LEVEL\n",
    "\n",
    "rto_month_counts = main_df.groupby(by = ['month', 'year', 'rto_name', 'state', 'state_symbol',\n",
    "                                         'rto_code'])['count'].sum().to_frame().reset_index().rename(columns = \n",
    "                                                                                                     {'count' :\n",
    "                                                                                                     'overall_count'})\n",
    "\n",
    "ev_counts = main_df[main_df['fuel'] == 'ELECTRIC(BOV)'][['month', 'year', 'rto_name', 'state', 'state_symbol',\n",
    "                                                'rto_code', 'count']]\n",
    "\n",
    "ev_counts = ev_counts.rename(columns = {'count' : 'ev_count'})\n",
    "\n",
    "# CREATING THE EV SHARES DATAFRAME\n",
    "\n",
    "ev_shares = pd.merge(rto_month_counts, ev_counts, on = ['month', 'year', 'rto_name',\n",
    "                                                        'rto_code', 'state', 'state_symbol'], how = 'outer')\n",
    "\n",
    "\n",
    "# FOR MONTHS WITH NO REGISTRATIONS BUT TO STILL CALCULATE THE FRACTION\n",
    "\n",
    "ev_shares['overall_count'] = ev_shares['overall_count'].replace(0, 1) \n",
    "\n",
    "ev_shares['ev_count'] = ev_shares['ev_count'].fillna(0).astype(int)\n",
    "ev_shares['ev_share'] = ((ev_shares['ev_count']/ev_shares['overall_count'])*100).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "974c03f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>rto_name</th>\n",
       "      <th>state</th>\n",
       "      <th>state_symbol</th>\n",
       "      <th>rto_code</th>\n",
       "      <th>overall_count</th>\n",
       "      <th>ev_count</th>\n",
       "      <th>ev_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APR</td>\n",
       "      <td>2010</td>\n",
       "      <td>AAHWA</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>GJ</td>\n",
       "      <td>GJ30</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APR</td>\n",
       "      <td>2010</td>\n",
       "      <td>ABOHAR SDM</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>PB</td>\n",
       "      <td>PB15</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APR</td>\n",
       "      <td>2010</td>\n",
       "      <td>ABU ROAD DTO</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>RJ</td>\n",
       "      <td>RJ38</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APR</td>\n",
       "      <td>2010</td>\n",
       "      <td>ADOOR SRTO</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>KL</td>\n",
       "      <td>KL26</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APR</td>\n",
       "      <td>2010</td>\n",
       "      <td>AGAR MALWA RTO</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>MP</td>\n",
       "      <td>MP70</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213859</th>\n",
       "      <td>SEP</td>\n",
       "      <td>2023</td>\n",
       "      <td>YANAM</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>PY</td>\n",
       "      <td>PY4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213860</th>\n",
       "      <td>SEP</td>\n",
       "      <td>2023</td>\n",
       "      <td>YAWATMAL</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>MH</td>\n",
       "      <td>MH29</td>\n",
       "      <td>3049</td>\n",
       "      <td>144</td>\n",
       "      <td>4.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213861</th>\n",
       "      <td>SEP</td>\n",
       "      <td>2023</td>\n",
       "      <td>YUPIA</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR2</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213862</th>\n",
       "      <td>SEP</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZIRA SDM</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>PB</td>\n",
       "      <td>PB47</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213863</th>\n",
       "      <td>SEP</td>\n",
       "      <td>2023</td>\n",
       "      <td>ZUNHEBOTO DTO</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213864 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       month  year        rto_name              state state_symbol rto_code  \\\n",
       "0        APR  2010           AAHWA            Gujarat           GJ     GJ30   \n",
       "1        APR  2010      ABOHAR SDM             Punjab           PB     PB15   \n",
       "2        APR  2010    ABU ROAD DTO          Rajasthan           RJ     RJ38   \n",
       "3        APR  2010      ADOOR SRTO             Kerala           KL     KL26   \n",
       "4        APR  2010  AGAR MALWA RTO     Madhya Pradesh           MP     MP70   \n",
       "...      ...   ...             ...                ...          ...      ...   \n",
       "213859   SEP  2023           YANAM         Puducherry           PY      PY4   \n",
       "213860   SEP  2023        YAWATMAL        Maharashtra           MH     MH29   \n",
       "213861   SEP  2023           YUPIA  Arunachal Pradesh           AR      AR2   \n",
       "213862   SEP  2023        ZIRA SDM             Punjab           PB     PB47   \n",
       "213863   SEP  2023   ZUNHEBOTO DTO           Nagaland           NL      NL6   \n",
       "\n",
       "        overall_count  ev_count  ev_share  \n",
       "0                  57         0     0.000  \n",
       "1                  86         0     0.000  \n",
       "2                 115         0     0.000  \n",
       "3                 334         0     0.000  \n",
       "4                 273         0     0.000  \n",
       "...               ...       ...       ...  \n",
       "213859              9         1    11.111  \n",
       "213860           3049       144     4.723  \n",
       "213861            180         0     0.000  \n",
       "213862            213         0     0.000  \n",
       "213863             11         0     0.000  \n",
       "\n",
       "[213864 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "822dffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPPING EACH OF THE RTOS TO THEIR RESPECTIVE DISTRICTS, WHILE TAKING CARE OF SOME NAMING DISCREPANCIES\n",
    "\n",
    "matching_districts = ev_shares[['rto_name']].drop_duplicates()\n",
    "matching_districts['rto_name'] = matching_districts['rto_name'].apply(lambda x: x.strip())\n",
    "\n",
    "updated_matching = pd.read_excel('Updated arcGIS RTO to district matching.xlsx')\n",
    "updated_matching = updated_matching[['rto_name', 'rto_name_y', 'rto_code', 'district']]\n",
    "full_match = pd.merge(matching_districts, updated_matching, on = 'rto_name')\n",
    "for i in range(len(full_match)):\n",
    "    if full_match['district'][i] == 'Angul':\n",
    "        full_match['district'][i] = 'Anugul'\n",
    "    elif full_match['district'][i] == 'Thoothukudi':\n",
    "        full_match['district'][i] = 'Tuticorin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23fef11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rto_name</th>\n",
       "      <th>rto_name_y</th>\n",
       "      <th>rto_code</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAHWA</td>\n",
       "      <td>AAHWA</td>\n",
       "      <td>GJ30</td>\n",
       "      <td>Dang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABOHAR SDM</td>\n",
       "      <td>ABOHAR SDM</td>\n",
       "      <td>PB15</td>\n",
       "      <td>Fazilka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABU ROAD DTO</td>\n",
       "      <td>ABU ROAD DTO</td>\n",
       "      <td>RJ38</td>\n",
       "      <td>Sirohi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADOOR SRTO</td>\n",
       "      <td>ADOOR SRTO</td>\n",
       "      <td>KL26</td>\n",
       "      <td>Pathanamthitta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGAR MALWA RTO</td>\n",
       "      <td>AGAR MALWA RTO</td>\n",
       "      <td>MP70</td>\n",
       "      <td>Agar Malwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>YANAM</td>\n",
       "      <td>YANAM</td>\n",
       "      <td>PY4</td>\n",
       "      <td>Yanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>YAWATMAL</td>\n",
       "      <td>YAWATMAL</td>\n",
       "      <td>MH29</td>\n",
       "      <td>Yavatmal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>YUPIA</td>\n",
       "      <td>YUPIA</td>\n",
       "      <td>AR2</td>\n",
       "      <td>Papum Pare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>ZIRA SDM</td>\n",
       "      <td>ZIRA SDM</td>\n",
       "      <td>PB47</td>\n",
       "      <td>Ferozepur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>ZUNHEBOTO DTO</td>\n",
       "      <td>ZUNHEBOTO DTO</td>\n",
       "      <td>NL6</td>\n",
       "      <td>Zunheboto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            rto_name      rto_name_y rto_code        district\n",
       "0              AAHWA           AAHWA     GJ30            Dang\n",
       "1         ABOHAR SDM      ABOHAR SDM     PB15         Fazilka\n",
       "2       ABU ROAD DTO    ABU ROAD DTO     RJ38          Sirohi\n",
       "3         ADOOR SRTO      ADOOR SRTO     KL26  Pathanamthitta\n",
       "4     AGAR MALWA RTO  AGAR MALWA RTO     MP70      Agar Malwa\n",
       "...              ...             ...      ...             ...\n",
       "1267           YANAM           YANAM      PY4           Yanam\n",
       "1268        YAWATMAL        YAWATMAL     MH29        Yavatmal\n",
       "1269           YUPIA           YUPIA      AR2      Papum Pare\n",
       "1270        ZIRA SDM        ZIRA SDM     PB47       Ferozepur\n",
       "1271   ZUNHEBOTO DTO   ZUNHEBOTO DTO      NL6       Zunheboto\n",
       "\n",
       "[1272 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22e91e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING DISTRICT INFORMATION TO THE ev_shares DATAFRAME CREATED A FEW CELLS ABOVE.\n",
    "\n",
    "# COMPARED TO EV_SHARES, WE LOSE 168 OBSERVATIONS AS WE DROP PUNJAB(STA) SINCE WE COULD NOT MATCH IT TO A DISTRICT\n",
    "district_data = pd.merge(ev_shares, full_match, on = ['rto_name'])\n",
    "\n",
    "district_data = district_data[['rto_name', 'rto_code_x', 'district', 'state', 'state_symbol',\n",
    "               'year', 'month', 'overall_count', 'ev_count', 'ev_share']].rename(columns = \n",
    "                                                                                 {'rto_code_x' : 'rto_code'})\n",
    "\n",
    "# CONTAINS THE CURRENT DISTRICT TO 2011 DISTRICT TO 2011 DISTRICT (IN DEMOGRAPHIC FILES) NAME CONVERSION\n",
    "\n",
    "districts_2011 = pd.read_csv('final_mapping.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "# RTOS MAPPED TO DISTRICTS\n",
    "\n",
    "mapped_districts = pd.merge(full_match, districts_2011, left_on = ['district'],\n",
    "         right_on = ['district_current (stage 1)'], how = 'left')\n",
    "\n",
    "mapped_districts = mapped_districts[['rto_name', 'district','district_current (stage 1)',\n",
    "                  'district_2011 (stage 2)']].drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "merged_df1 = pd.merge(district_data, mapped_districts, on = ['rto_name', 'district'])\n",
    "merged_df1['district_2011 (stage 2)'] = merged_df1['district_2011 (stage 2)'] + ', ' + merged_df1['state_symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1074e961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rto_name</th>\n",
       "      <th>rto_code</th>\n",
       "      <th>district</th>\n",
       "      <th>state</th>\n",
       "      <th>state_symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>overall_count</th>\n",
       "      <th>ev_count</th>\n",
       "      <th>ev_share</th>\n",
       "      <th>district_current (stage 1)</th>\n",
       "      <th>district_2011 (stage 2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAHWA</td>\n",
       "      <td>GJ30</td>\n",
       "      <td>Dang</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>GJ</td>\n",
       "      <td>2010</td>\n",
       "      <td>APR</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dang</td>\n",
       "      <td>The Dangs, GJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAHWA</td>\n",
       "      <td>GJ30</td>\n",
       "      <td>Dang</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>GJ</td>\n",
       "      <td>2011</td>\n",
       "      <td>APR</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dang</td>\n",
       "      <td>The Dangs, GJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAHWA</td>\n",
       "      <td>GJ30</td>\n",
       "      <td>Dang</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>GJ</td>\n",
       "      <td>2012</td>\n",
       "      <td>APR</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dang</td>\n",
       "      <td>The Dangs, GJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAHWA</td>\n",
       "      <td>GJ30</td>\n",
       "      <td>Dang</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>GJ</td>\n",
       "      <td>2013</td>\n",
       "      <td>APR</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dang</td>\n",
       "      <td>The Dangs, GJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAHWA</td>\n",
       "      <td>GJ30</td>\n",
       "      <td>Dang</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>GJ</td>\n",
       "      <td>2014</td>\n",
       "      <td>APR</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dang</td>\n",
       "      <td>The Dangs, GJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213691</th>\n",
       "      <td>ZUNHEBOTO DTO</td>\n",
       "      <td>NL6</td>\n",
       "      <td>Zunheboto</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>2019</td>\n",
       "      <td>SEP</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zunheboto</td>\n",
       "      <td>Zunheboto, NL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213692</th>\n",
       "      <td>ZUNHEBOTO DTO</td>\n",
       "      <td>NL6</td>\n",
       "      <td>Zunheboto</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>2020</td>\n",
       "      <td>SEP</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zunheboto</td>\n",
       "      <td>Zunheboto, NL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213693</th>\n",
       "      <td>ZUNHEBOTO DTO</td>\n",
       "      <td>NL6</td>\n",
       "      <td>Zunheboto</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>2021</td>\n",
       "      <td>SEP</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zunheboto</td>\n",
       "      <td>Zunheboto, NL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213694</th>\n",
       "      <td>ZUNHEBOTO DTO</td>\n",
       "      <td>NL6</td>\n",
       "      <td>Zunheboto</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>2022</td>\n",
       "      <td>SEP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zunheboto</td>\n",
       "      <td>Zunheboto, NL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213695</th>\n",
       "      <td>ZUNHEBOTO DTO</td>\n",
       "      <td>NL6</td>\n",
       "      <td>Zunheboto</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>2023</td>\n",
       "      <td>SEP</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zunheboto</td>\n",
       "      <td>Zunheboto, NL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213696 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rto_name rto_code   district     state state_symbol  year month  \\\n",
       "0               AAHWA     GJ30       Dang   Gujarat           GJ  2010   APR   \n",
       "1               AAHWA     GJ30       Dang   Gujarat           GJ  2011   APR   \n",
       "2               AAHWA     GJ30       Dang   Gujarat           GJ  2012   APR   \n",
       "3               AAHWA     GJ30       Dang   Gujarat           GJ  2013   APR   \n",
       "4               AAHWA     GJ30       Dang   Gujarat           GJ  2014   APR   \n",
       "...               ...      ...        ...       ...          ...   ...   ...   \n",
       "213691  ZUNHEBOTO DTO      NL6  Zunheboto  Nagaland           NL  2019   SEP   \n",
       "213692  ZUNHEBOTO DTO      NL6  Zunheboto  Nagaland           NL  2020   SEP   \n",
       "213693  ZUNHEBOTO DTO      NL6  Zunheboto  Nagaland           NL  2021   SEP   \n",
       "213694  ZUNHEBOTO DTO      NL6  Zunheboto  Nagaland           NL  2022   SEP   \n",
       "213695  ZUNHEBOTO DTO      NL6  Zunheboto  Nagaland           NL  2023   SEP   \n",
       "\n",
       "        overall_count  ev_count  ev_share district_current (stage 1)  \\\n",
       "0                  57         0       0.0                       Dang   \n",
       "1                  54         0       0.0                       Dang   \n",
       "2                  67         0       0.0                       Dang   \n",
       "3                 219         0       0.0                       Dang   \n",
       "4                 265         0       0.0                       Dang   \n",
       "...               ...       ...       ...                        ...   \n",
       "213691              6         0       0.0                  Zunheboto   \n",
       "213692              9         0       0.0                  Zunheboto   \n",
       "213693              9         0       0.0                  Zunheboto   \n",
       "213694              1         0       0.0                  Zunheboto   \n",
       "213695             11         0       0.0                  Zunheboto   \n",
       "\n",
       "       district_2011 (stage 2)  \n",
       "0                The Dangs, GJ  \n",
       "1                The Dangs, GJ  \n",
       "2                The Dangs, GJ  \n",
       "3                The Dangs, GJ  \n",
       "4                The Dangs, GJ  \n",
       "...                        ...  \n",
       "213691           Zunheboto, NL  \n",
       "213692           Zunheboto, NL  \n",
       "213693           Zunheboto, NL  \n",
       "213694           Zunheboto, NL  \n",
       "213695           Zunheboto, NL  \n",
       "\n",
       "[213696 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a303a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FURTHER RECONCILING NAMING DIFFERENCES ACROSS DIFFERENT DATAFRAMES\n",
    "\n",
    "for i in range(len(merged_df1)):\n",
    "    \n",
    "    if merged_df1['district_2011 (stage 2)'][i] == 'Ahmedabad/Bhavnagar, GJ':\n",
    "        merged_df1['district_2011 (stage 2)'][i] = 'Ahmadabad/Bhavnagar, GJ'\n",
    "        \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] == 'Leh (Ladakh), LA':\n",
    "        merged_df1['district_2011 (stage 2)'][i] = 'Leh (Ladakh), JK'\n",
    "        merged_df1['state_symbol'][i] = 'JK'\n",
    "        \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] == 'Kargil, LA':\n",
    "        merged_df1['district_2011 (stage 2)'][i] = 'Kargil, JK'\n",
    "        merged_df1['state_symbol'][i] = 'JK'    \n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] == 'Balrampur, CG':\n",
    "        merged_df1['district_2011 (stage 2)'][i] = 'Surguja, CG'\n",
    "        merged_df1['state_symbol'][i] = 'CG' \n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] == 'East Godavari , AP':\n",
    "        merged_df1['district_2011 (stage 2)'][i] = 'East Godavari, AP'\n",
    "        merged_df1['state_symbol'][i] = 'AP' \n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] == 'Panch Mahals, GJ':\n",
    "        merged_df1['district_2011 (stage 2)'][i] = 'Panchmahal, GJ'\n",
    "        merged_df1['state_symbol'][i] = 'GJ' \n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] == 'Panchmahals, GJ':\n",
    "        merged_df1['district_2011 (stage 2)'][i] = 'Panchmahal, GJ'\n",
    "        merged_df1['state_symbol'][i] = 'GJ'\n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] == 'Panch mahal, GJ':\n",
    "        merged_df1['district_2011 (stage 2)'][i] = 'Panchmahal, GJ'\n",
    "        merged_df1['state_symbol'][i] = 'GJ'\n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] == 'Gurgaon , HR':\n",
    "        merged_df1['district_2011 (stage 2)'][i] = 'Gurgaon, HR'\n",
    "        merged_df1['state_symbol'][i] = 'HR'\n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] == 'Chandigarh, HR':\n",
    "        merged_df1['district_2011 (stage 2)'][i] = 'Chandigarh, CH'\n",
    "        merged_df1['state_symbol'][i] = 'CH'\n",
    "        merged_df1['state'][i] = 'Chandigarh'\n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] == 'Multiple, GJ':\n",
    "        merged_df1['district_2011 (stage 2)'][i] = 'Surendranagar/Rajkot, GJ'\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5992a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Rae Bareli, UP', 'Sultanpur, UP'},\n",
       " {'Ahmadabad, GJ', 'Bhavnagar, GJ'},\n",
       " {'Faridabad, HR', 'Gurgaon, HR'},\n",
       " {'Kheda, GJ', 'Panchmahal, GJ'},\n",
       " {'Rajkot, GJ', 'Surendranagar, GJ'},\n",
       " {'Chittoor, AP', 'Y.S.R., AP'},\n",
       " {'Srikakulam, AP', 'Vizianagaram, AP'},\n",
       " {'Budaun, UP', 'Moradabad, UP'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTICING THAT SOME RTOS BELONG TO DISTRICTS THAT ARE COMPOSED OF MULTIPLE 2011 DISTRICTS, WE NEED TO MAP THAT\n",
    "# RTO'S FIGURES TO THE AMALGAMATION OF THE MULTIPLE DISTRICTS. IN OUR CONTEXT, THE MAXIMUM DISTRICTS THAT A SINGLE\n",
    "# RTO BELONGS TO IS 2. HENCE, WE CREATE A SECOND COLUMN NAMED district_2011 (stage 2.1) TO KEEP TRACK OF THAT.\n",
    "\n",
    "merged_df1['district_2011 (stage 2.1)'] = np.nan\n",
    "for i in range(len(merged_df1)):\n",
    "    if '/' in merged_df1['district_2011 (stage 2)'][i]:\n",
    "        merged_df1['district_2011 (stage 2.1)'][i] = merged_df1['district_2011 (stage 2)'][i].split('/')[1]\n",
    "    else:\n",
    "        merged_df1['district_2011 (stage 2.1)'][i] = merged_df1['district_2011 (stage 2)'][i]\n",
    "\n",
    "# leaves only 1 district in the first column\n",
    "for i in range(len(merged_df1)):\n",
    "    if '/' in merged_df1['district_2011 (stage 2)'][i]:\n",
    "        merged_df1['district_2011 (stage 2)'][i] = merged_df1['district_2011 (stage 2)'][i].split('/')[0] + ', ' + merged_df1['state_symbol'][i]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "# Function to get unique values from two columns in a row\n",
    "def get_unique_values(row):\n",
    "    return set([row['district_2011 (stage 2)'],row['district_2011 (stage 2.1)']])\n",
    "\n",
    "# Apply the function to create a new column 'unique_districts'\n",
    "merged_df1['unique_districts'] = merged_df1.apply(get_unique_values, axis=1)\n",
    "\n",
    "# create the necessary groupings\n",
    "groupings = []\n",
    "for i in range(len(merged_df1)):\n",
    "    if len(merged_df1['unique_districts'][i]) == 2:\n",
    "        groupings.append(merged_df1['unique_districts'][i])\n",
    "\n",
    "# function to get unique values\n",
    "def unique_elements(list1):\n",
    "\n",
    "# initialize a null list\n",
    "    unique_list = []\n",
    "\n",
    "# traverse for all elements\n",
    "    for x in list1:\n",
    "# check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return unique_list\n",
    "\n",
    "unique_elements(groupings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9e226f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING THE GROUPINGS BASED ON THE OUTPUT OF THE unique_elements FUNCTION\n",
    "\n",
    "merged_df1['grouped_district'] = np.nan\n",
    "for i in range(len(merged_df1)):\n",
    "    if merged_df1['district_2011 (stage 2)'][i] in {'Ahmadabad, GJ', 'Bhavnagar, GJ'}:\n",
    "        merged_df1['grouped_district'][i] = 'Ahmadabad + Bhavnagar, GJ'\n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] in {'Chittoor, AP', 'Y.S.R., AP'}:\n",
    "        merged_df1['grouped_district'][i] = 'Chittoor + Y.S.R., AP'\n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] in {'Faridabad, HR', 'Gurgaon, HR'}:\n",
    "        merged_df1['grouped_district'][i] = 'Faridabad + Gurgaon, HR'\n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] in {'Kheda, GJ', 'Panchmahal, GJ'}:\n",
    "        merged_df1['grouped_district'][i] = 'Kheda + Panchmahal, GJ'\n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] in {'Budaun, UP', 'Moradabad, UP'}:\n",
    "        merged_df1['grouped_district'][i] = 'Budaun + Moradabad, UP'\n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] in {'Rajkot, GJ', 'Surendranagar, GJ'}:\n",
    "        merged_df1['grouped_district'][i] = 'Rajkot + Surendranagar, GJ'\n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] in {'Rae Bareli, UP', 'Sultanpur, UP'}:\n",
    "        merged_df1['grouped_district'][i] = 'Rae Bareli + Sultanpur, UP'\n",
    "    \n",
    "    elif merged_df1['district_2011 (stage 2)'][i] in {'Srikakulam, AP', 'Vizianagaram, AP'}:\n",
    "        merged_df1['grouped_district'][i] = 'Srikakulam + Vizianagaram, AP'\n",
    "    \n",
    "    else:\n",
    "        merged_df1['grouped_district'][i] = merged_df1['district_2011 (stage 2)'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c80edc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING THE EV SHARES FOR EACH GROUPED DISTRICT\n",
    "merged_df2 = merged_df1[['rto_name', 'rto_code', 'grouped_district', 'state', 'state_symbol',\n",
    "           'year', 'month', 'overall_count', 'ev_count', 'ev_share']]\n",
    "\n",
    "merged_df3 = merged_df2.groupby(by = ['grouped_district', 'year', 'state', 'state_symbol',\n",
    "                         'month',]).agg({'overall_count' : 'sum', 'ev_count' : 'sum'}).reset_index()\n",
    "\n",
    "merged_df3['ev_share'] = (merged_df3['ev_count']/merged_df3['overall_count'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee42e677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grouped_district</th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>state_symbol</th>\n",
       "      <th>month</th>\n",
       "      <th>overall_count</th>\n",
       "      <th>ev_count</th>\n",
       "      <th>ev_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2010</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>UP</td>\n",
       "      <td>APR</td>\n",
       "      <td>2165</td>\n",
       "      <td>2</td>\n",
       "      <td>0.092379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2010</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>UP</td>\n",
       "      <td>AUG</td>\n",
       "      <td>4212</td>\n",
       "      <td>5</td>\n",
       "      <td>0.118708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2010</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>UP</td>\n",
       "      <td>DEC</td>\n",
       "      <td>4943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2010</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>UP</td>\n",
       "      <td>FEB</td>\n",
       "      <td>3667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2010</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>UP</td>\n",
       "      <td>JAN</td>\n",
       "      <td>5247</td>\n",
       "      <td>3</td>\n",
       "      <td>0.057176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100963</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>MAR</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100964</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>MAY</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100965</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>NOV</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100966</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>OCT</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100967</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>SEP</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100968 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grouped_district  year          state state_symbol month  \\\n",
       "0              Agra, UP  2010  Uttar Pradesh           UP   APR   \n",
       "1              Agra, UP  2010  Uttar Pradesh           UP   AUG   \n",
       "2              Agra, UP  2010  Uttar Pradesh           UP   DEC   \n",
       "3              Agra, UP  2010  Uttar Pradesh           UP   FEB   \n",
       "4              Agra, UP  2010  Uttar Pradesh           UP   JAN   \n",
       "...                 ...   ...            ...          ...   ...   \n",
       "100963    Zunheboto, NL  2023       Nagaland           NL   MAR   \n",
       "100964    Zunheboto, NL  2023       Nagaland           NL   MAY   \n",
       "100965    Zunheboto, NL  2023       Nagaland           NL   NOV   \n",
       "100966    Zunheboto, NL  2023       Nagaland           NL   OCT   \n",
       "100967    Zunheboto, NL  2023       Nagaland           NL   SEP   \n",
       "\n",
       "        overall_count  ev_count  ev_share  \n",
       "0                2165         2  0.092379  \n",
       "1                4212         5  0.118708  \n",
       "2                4943         1  0.020231  \n",
       "3                3667         0  0.000000  \n",
       "4                5247         3  0.057176  \n",
       "...               ...       ...       ...  \n",
       "100963             66         0  0.000000  \n",
       "100964             83         0  0.000000  \n",
       "100965            116         0  0.000000  \n",
       "100966             86         0  0.000000  \n",
       "100967             54         0  0.000000  \n",
       "\n",
       "[100968 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registrations_dataset = merged_df3.copy()\n",
    "registrations_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87235a3e",
   "metadata": {},
   "source": [
    "# Section 2: Creating shapefiles for grouped districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba17869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING THE SHAPEFILE CONTAINING BOUNDARIES FOR INDIVIDUAL DISTRICTS ACCORDING TO 2011 CENSUS\n",
    "\n",
    "shapefiles = zf.ZipFile('2011 districts datameet boundaries.zip', 'r')\n",
    "shapefiles.extractall('district shapefiles')\n",
    "gdf_districts = gpd.read_file('district shapefiles/India-Districts-2011Census.shp')\n",
    "\n",
    "state_symbol_dict = {'Andhra Pradesh' : 'AP', 'Uttar Pradesh' : 'UP', 'Gujarat' : 'GJ', 'Maharashtra' : 'MH',\n",
    "                    'Mizoram' : 'MZ', 'Rajasthan' : 'RJ', 'Kerala' : 'KL', 'Madhya Pradesh' : 'MP',\n",
    "                    'Uttarakhand' : 'UK', 'Haryana' : 'HR', 'Punjab' : 'PB', 'Jammu & Kashmir' : 'JK',\n",
    "                    'Arunanchal Pradesh' : 'AR', 'Odisha' : 'OR', 'Bihar' : 'BR', 'Tamil Nadu' : 'TN',\n",
    "                    'Karnataka' : 'KA', 'Assam' : 'AS', 'West Bengal' : 'WB', 'Chhattisgarh' : 'CG',\n",
    "                     'Himachal Pradesh' : 'HP', 'Manipur' : 'MN', 'Jharkhand' : 'JH', 'NCT of Delhi' : 'DL',\n",
    "                     'Chandigarh' : 'CH', 'Dadara & Nagar Havelli' : 'DD', 'Daman & Diu' : 'DD', 'Tripura' : 'TR',\n",
    "                     'Nagaland' : 'NL', 'Sikkim' : 'SK', 'Meghalaya' : 'ML', 'Puducherry' : 'PY',\n",
    "                     'Lakshadweep' : 'LD', 'Andaman & Nicobar Island' : 'AN', 'Goa' : 'GA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8c96f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>ST_NM</th>\n",
       "      <th>ST_CEN_CD</th>\n",
       "      <th>DT_CEN_CD</th>\n",
       "      <th>censuscode</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adilabad</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>532</td>\n",
       "      <td>POLYGON ((78.84972 19.76010, 78.85102 19.75945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>146</td>\n",
       "      <td>POLYGON ((78.19803 27.40280, 78.19804 27.40278...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmadabad</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>474</td>\n",
       "      <td>MULTIPOLYGON (((72.03456 23.50527, 72.03337 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmadnagar</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>522</td>\n",
       "      <td>POLYGON ((74.67333 19.94670, 74.67393 19.93509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aizawl</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>283</td>\n",
       "      <td>POLYGON ((92.98749 24.40453, 92.99107 24.40236...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Tapi</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>493</td>\n",
       "      <td>POLYGON ((74.08573 21.55513, 74.08672 21.55515...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Nicobar</td>\n",
       "      <td>Andaman &amp; Nicobar Island</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>638</td>\n",
       "      <td>MULTIPOLYGON (((93.84861 7.24051, 93.84870 7.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>South Andaman</td>\n",
       "      <td>Andaman &amp; Nicobar Island</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>MULTIPOLYGON (((92.69758 12.23961, 92.69778 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>North &amp; Middle Andaman</td>\n",
       "      <td>Andaman &amp; Nicobar Island</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>639</td>\n",
       "      <td>MULTIPOLYGON (((92.89905 12.91512, 92.89905 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>Lakshadweep</td>\n",
       "      <td>Lakshadweep</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>587</td>\n",
       "      <td>MULTIPOLYGON (((74.10131 11.20431, 74.09908 11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>641 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DISTRICT                     ST_NM  ST_CEN_CD  DT_CEN_CD  \\\n",
       "0                  Adilabad            Andhra Pradesh         28          1   \n",
       "1                      Agra             Uttar Pradesh          9         15   \n",
       "2                 Ahmadabad                   Gujarat         24          7   \n",
       "3                Ahmadnagar               Maharashtra         27         26   \n",
       "4                    Aizawl                   Mizoram         15          3   \n",
       "..                      ...                       ...        ...        ...   \n",
       "636                    Tapi                   Gujarat         24         26   \n",
       "637                 Nicobar  Andaman & Nicobar Island         35          1   \n",
       "638           South Andaman  Andaman & Nicobar Island         35          3   \n",
       "639  North & Middle Andaman  Andaman & Nicobar Island         35          2   \n",
       "640             Lakshadweep               Lakshadweep         31          1   \n",
       "\n",
       "    censuscode                                           geometry  \n",
       "0          532  POLYGON ((78.84972 19.76010, 78.85102 19.75945...  \n",
       "1          146  POLYGON ((78.19803 27.40280, 78.19804 27.40278...  \n",
       "2          474  MULTIPOLYGON (((72.03456 23.50527, 72.03337 23...  \n",
       "3          522  POLYGON ((74.67333 19.94670, 74.67393 19.93509...  \n",
       "4          283  POLYGON ((92.98749 24.40453, 92.99107 24.40236...  \n",
       "..         ...                                                ...  \n",
       "636        493  POLYGON ((74.08573 21.55513, 74.08672 21.55515...  \n",
       "637        638  MULTIPOLYGON (((93.84861 7.24051, 93.84870 7.2...  \n",
       "638        640  MULTIPOLYGON (((92.69758 12.23961, 92.69778 12...  \n",
       "639        639  MULTIPOLYGON (((92.89905 12.91512, 92.89905 12...  \n",
       "640        587  MULTIPOLYGON (((74.10131 11.20431, 74.09908 11...  \n",
       "\n",
       "[641 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b28e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECONCILING NAMING CONVENTIONS FOR SHAPEFILE MERGING LATER\n",
    "\n",
    "gdf_districts['state_symbol'] = np.nan\n",
    "for i in range(len(gdf_districts)):\n",
    "    gdf_districts['state_symbol'][i] = state_symbol_dict[gdf_districts['ST_NM'][i]]\n",
    "\n",
    "for i in range(len(gdf_districts)):\n",
    "    gdf_districts['DISTRICT'][i] = gdf_districts['DISTRICT'][i] + ', ' + gdf_districts['state_symbol'][i]\n",
    "    \n",
    "df_for_gis_group_mapping = pd.read_excel('correct district naming.xlsx').drop(columns = 'Unnamed: 0').dropna()\n",
    "gdf_districts = gdf_districts.merge(df_for_gis_group_mapping, on = 'DISTRICT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba00047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE GOAL IS TO CREATE BOUNDARIES FOR AMALGAMATED DISTRICTS USING THE BOUNDARIES FOR INDIVIDUAL DISTRICTS. FOR\n",
    "# THAT, WE CREATE 2 SEPERATE SHAPEFILES: merge_set1 CONTAINS BOUNDARIES FOR THE FIRST DISTRICT AND merge_set2 \n",
    "# CONTAINS BOUNDARIES FOR THE SECOND DISTRICT. IN CASES WHERE THE FIRST AND SECOND DISTRICT IS THE SAME, THE\n",
    "# BOUNDARIES ARE ALSO THE SAME\n",
    "\n",
    "merging_partner = merged_df1[['district_2011 (stage 2)', 'district_2011 (stage 2.1)',\n",
    "                              'unique_districts', 'grouped_district']]\n",
    "merging_partner['unique_districts'] = merging_partner['unique_districts'].apply(frozenset)\n",
    "merging_partner = merging_partner.drop_duplicates()\n",
    "\n",
    "merge_set1 = gdf_districts.merge(merging_partner, left_on = 'DISTRICT (FOR MERGING)',\n",
    "                                 right_on = 'district_2011 (stage 2)', how = 'right')\n",
    "\n",
    "merge_set1 = merge_set1[['DISTRICT (FOR MERGING)', 'state_symbol', 'geometry', 'district_2011 (stage 2)',\n",
    "          'district_2011 (stage 2.1)', 'unique_districts', 'grouped_district']]\n",
    "\n",
    "merge_set2 = gdf_districts.merge(merging_partner, left_on = 'DISTRICT (FOR MERGING)',\n",
    "                                 right_on = 'district_2011 (stage 2.1)', how = 'right')\n",
    "\n",
    "merge_set2 = merge_set2[['DISTRICT (FOR MERGING)', 'state_symbol', 'geometry', 'district_2011 (stage 2)',\n",
    "          'district_2011 (stage 2.1)', 'unique_districts', 'grouped_district']]\n",
    "\n",
    "merge_set3 = merge_set1.merge(merge_set2, on = ['grouped_district', 'unique_districts']).reset_index(drop = True)\n",
    "\n",
    "merge_set4 = pd.DataFrame(columns = merge_set3.columns)\n",
    "for i in range(len(merge_set3)):\n",
    "    # EVEN IF THERE IS A ROW WITH AN ENTRY FOR AHMEDABAD, IT NEEDS TO BE MAPPED TO AHMEDABAD + BHAVNAGAR. WE FILTER\n",
    "    # THESE CASES OUT. \n",
    "    if (len(merge_set3['unique_districts'][i]) != 2) & ('+' in merge_set3['grouped_district'][i]):\n",
    "        pass\n",
    "    else:\n",
    "        merge_set4.loc[len(merge_set4)] = merge_set3.iloc[i]\n",
    "        \n",
    "\n",
    "# HERE, WE TAKE A UNION OF THE BOUNDARIES OF THE DIFFERENT DISTRICTS. IN CASE OF ONLY 1 SINGLE UNIQUE DISTRICT,\n",
    "# THE UNION WOULD RETURN THE SAME BOUNDARY.\n",
    "merge_set5 = merge_set4[['grouped_district', 'geometry_x', 'geometry_y', 'state_symbol_x']]\n",
    "merge_set5['group_geometry'] = np.nan\n",
    "for i in range(len(merge_set5)):\n",
    "    poly1 = merge_set5['geometry_x'][i]\n",
    "    poly2 = merge_set5['geometry_y'][i]\n",
    "    poly = poly1.union(poly2)\n",
    "    merge_set5['group_geometry'][i] = poly\n",
    "    \n",
    "merge_set5 = merge_set5.drop(columns = ['geometry_x', 'geometry_y'])\n",
    "merge_set5 = merge_set5.rename(columns = {'state_symbol_x' : 'state_symbol'})\n",
    "\n",
    "merge_set5 = gpd.GeoDataFrame(merge_set5, geometry = 'group_geometry', crs = merge_set1.crs)\n",
    "\n",
    "merge_set5.to_file('grouped district boundaries.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b2b5f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grouped_district</th>\n",
       "      <th>state_symbol</th>\n",
       "      <th>group_geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Dangs, GJ</td>\n",
       "      <td>GJ</td>\n",
       "      <td>MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Firozpur, PB</td>\n",
       "      <td>PB</td>\n",
       "      <td>POLYGON ((75.05354 31.15226, 75.05906 31.15277...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sirohi, RJ</td>\n",
       "      <td>RJ</td>\n",
       "      <td>MULTIPOLYGON (((72.84697 25.27216, 72.85327 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pathanamthitta, KL</td>\n",
       "      <td>KL</td>\n",
       "      <td>POLYGON ((77.28459 9.26677, 77.28269 9.26419, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shajapur, MP</td>\n",
       "      <td>MP</td>\n",
       "      <td>POLYGON ((76.22003 24.20257, 76.22684 24.17658...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Pashchimi Singhbhum, JH</td>\n",
       "      <td>JH</td>\n",
       "      <td>POLYGON ((85.51684 22.80854, 85.53084 22.80804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Wokha, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>POLYGON ((94.31711 26.45509, 94.31110 26.44707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Yadgir, KA</td>\n",
       "      <td>KA</td>\n",
       "      <td>POLYGON ((77.46166 16.88292, 77.46439 16.85820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Yanam, PY</td>\n",
       "      <td>PY</td>\n",
       "      <td>POLYGON ((82.22431 16.73626, 82.22997 16.72939...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Yavatmal, MH</td>\n",
       "      <td>MH</td>\n",
       "      <td>POLYGON ((78.27840 20.69391, 78.27733 20.68787...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>601 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            grouped_district state_symbol  \\\n",
       "0              The Dangs, GJ           GJ   \n",
       "1               Firozpur, PB           PB   \n",
       "2                 Sirohi, RJ           RJ   \n",
       "3         Pathanamthitta, KL           KL   \n",
       "4               Shajapur, MP           MP   \n",
       "..                       ...          ...   \n",
       "596  Pashchimi Singhbhum, JH           JH   \n",
       "597                Wokha, NL           NL   \n",
       "598               Yadgir, KA           KA   \n",
       "599                Yanam, PY           PY   \n",
       "600             Yavatmal, MH           MH   \n",
       "\n",
       "                                        group_geometry  \n",
       "0    MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...  \n",
       "1    POLYGON ((75.05354 31.15226, 75.05906 31.15277...  \n",
       "2    MULTIPOLYGON (((72.84697 25.27216, 72.85327 25...  \n",
       "3    POLYGON ((77.28459 9.26677, 77.28269 9.26419, ...  \n",
       "4    POLYGON ((76.22003 24.20257, 76.22684 24.17658...  \n",
       "..                                                 ...  \n",
       "596  POLYGON ((85.51684 22.80854, 85.53084 22.80804...  \n",
       "597  POLYGON ((94.31711 26.45509, 94.31110 26.44707...  \n",
       "598  POLYGON ((77.46166 16.88292, 77.46439 16.85820...  \n",
       "599  POLYGON ((82.22431 16.73626, 82.22997 16.72939...  \n",
       "600  POLYGON ((78.27840 20.69391, 78.27733 20.68787...  \n",
       "\n",
       "[601 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_district_boundaries = merge_set5.copy()\n",
    "grouped_district_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6c8f76",
   "metadata": {},
   "source": [
    "# Section 3: Meteorological variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a271b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING THE DIRECTORY CALLED weather data, APPENDING ALL THE FILES TOGETHER INTO A SINGLE LARGE DATAFRAME CALLED\n",
    "# weather_df.\n",
    "weather_files = os.listdir('weather data')\n",
    "weather_files.sort()\n",
    "\n",
    "weather_df = pd.read_excel('weather data/' + weather_files[0])\n",
    "for i in range(1, len(weather_files)):\n",
    "    to_add_weather_df = pd.read_excel('weather data/' + weather_files[i])\n",
    "    weather_df = pd.concat([weather_df, to_add_weather_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4e8befc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARAMETER</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>JAN</th>\n",
       "      <th>FEB</th>\n",
       "      <th>MAR</th>\n",
       "      <th>APR</th>\n",
       "      <th>MAY</th>\n",
       "      <th>JUN</th>\n",
       "      <th>JUL</th>\n",
       "      <th>AUG</th>\n",
       "      <th>SEP</th>\n",
       "      <th>OCT</th>\n",
       "      <th>NOV</th>\n",
       "      <th>DEC</th>\n",
       "      <th>ANN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2M</td>\n",
       "      <td>2010</td>\n",
       "      <td>24.25</td>\n",
       "      <td>77.25</td>\n",
       "      <td>17.07</td>\n",
       "      <td>20.66</td>\n",
       "      <td>28.10</td>\n",
       "      <td>32.78</td>\n",
       "      <td>35.79</td>\n",
       "      <td>34.17</td>\n",
       "      <td>27.96</td>\n",
       "      <td>26.88</td>\n",
       "      <td>25.55</td>\n",
       "      <td>24.42</td>\n",
       "      <td>21.24</td>\n",
       "      <td>15.97</td>\n",
       "      <td>25.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2M</td>\n",
       "      <td>2010</td>\n",
       "      <td>24.25</td>\n",
       "      <td>77.75</td>\n",
       "      <td>16.64</td>\n",
       "      <td>20.45</td>\n",
       "      <td>28.05</td>\n",
       "      <td>32.83</td>\n",
       "      <td>35.78</td>\n",
       "      <td>34.17</td>\n",
       "      <td>27.91</td>\n",
       "      <td>26.83</td>\n",
       "      <td>25.53</td>\n",
       "      <td>24.12</td>\n",
       "      <td>20.89</td>\n",
       "      <td>15.69</td>\n",
       "      <td>25.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T2M</td>\n",
       "      <td>2010</td>\n",
       "      <td>24.25</td>\n",
       "      <td>78.25</td>\n",
       "      <td>16.46</td>\n",
       "      <td>20.65</td>\n",
       "      <td>28.33</td>\n",
       "      <td>33.24</td>\n",
       "      <td>36.12</td>\n",
       "      <td>34.49</td>\n",
       "      <td>28.20</td>\n",
       "      <td>27.02</td>\n",
       "      <td>25.76</td>\n",
       "      <td>24.18</td>\n",
       "      <td>20.92</td>\n",
       "      <td>15.70</td>\n",
       "      <td>25.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T2M</td>\n",
       "      <td>2010</td>\n",
       "      <td>24.25</td>\n",
       "      <td>78.75</td>\n",
       "      <td>16.11</td>\n",
       "      <td>20.56</td>\n",
       "      <td>28.31</td>\n",
       "      <td>33.30</td>\n",
       "      <td>36.00</td>\n",
       "      <td>34.43</td>\n",
       "      <td>28.27</td>\n",
       "      <td>26.99</td>\n",
       "      <td>25.82</td>\n",
       "      <td>24.08</td>\n",
       "      <td>20.87</td>\n",
       "      <td>15.62</td>\n",
       "      <td>25.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T2M</td>\n",
       "      <td>2010</td>\n",
       "      <td>24.25</td>\n",
       "      <td>79.25</td>\n",
       "      <td>15.72</td>\n",
       "      <td>20.57</td>\n",
       "      <td>28.48</td>\n",
       "      <td>33.58</td>\n",
       "      <td>36.23</td>\n",
       "      <td>34.73</td>\n",
       "      <td>28.65</td>\n",
       "      <td>27.19</td>\n",
       "      <td>25.95</td>\n",
       "      <td>24.17</td>\n",
       "      <td>20.95</td>\n",
       "      <td>15.61</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19850</th>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>2022</td>\n",
       "      <td>9.75</td>\n",
       "      <td>80.25</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5.21</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.78</td>\n",
       "      <td>5.85</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.81</td>\n",
       "      <td>9.04</td>\n",
       "      <td>9.43</td>\n",
       "      <td>7.85</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19851</th>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>2022</td>\n",
       "      <td>9.75</td>\n",
       "      <td>80.75</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.06</td>\n",
       "      <td>5.03</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.79</td>\n",
       "      <td>5.52</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.05</td>\n",
       "      <td>9.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>8.68</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19852</th>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>2022</td>\n",
       "      <td>9.75</td>\n",
       "      <td>81.25</td>\n",
       "      <td>2.55</td>\n",
       "      <td>3.71</td>\n",
       "      <td>1.55</td>\n",
       "      <td>5.89</td>\n",
       "      <td>2.59</td>\n",
       "      <td>1.95</td>\n",
       "      <td>5.43</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.16</td>\n",
       "      <td>8.43</td>\n",
       "      <td>7.85</td>\n",
       "      <td>10.82</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19853</th>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>2022</td>\n",
       "      <td>9.75</td>\n",
       "      <td>81.75</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2.54</td>\n",
       "      <td>7.28</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.31</td>\n",
       "      <td>5.26</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2.19</td>\n",
       "      <td>8.42</td>\n",
       "      <td>5.91</td>\n",
       "      <td>13.61</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19854</th>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>2022</td>\n",
       "      <td>9.75</td>\n",
       "      <td>82.25</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.90</td>\n",
       "      <td>6.28</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.60</td>\n",
       "      <td>4.73</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.99</td>\n",
       "      <td>4.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359125 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PARAMETER  YEAR    LAT    LON    JAN    FEB    MAR    APR    MAY  \\\n",
       "0              T2M  2010  24.25  77.25  17.07  20.66  28.10  32.78  35.79   \n",
       "1              T2M  2010  24.25  77.75  16.64  20.45  28.05  32.83  35.78   \n",
       "2              T2M  2010  24.25  78.25  16.46  20.65  28.33  33.24  36.12   \n",
       "3              T2M  2010  24.25  78.75  16.11  20.56  28.31  33.30  36.00   \n",
       "4              T2M  2010  24.25  79.25  15.72  20.57  28.48  33.58  36.23   \n",
       "...            ...   ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "19850  PRECTOTCORR  2022   9.75  80.25   2.70   2.83   0.79   5.21   1.91   \n",
       "19851  PRECTOTCORR  2022   9.75  80.75   2.63   3.58   1.06   5.03   2.29   \n",
       "19852  PRECTOTCORR  2022   9.75  81.25   2.55   3.71   1.55   5.89   2.59   \n",
       "19853  PRECTOTCORR  2022   9.75  81.75   2.54   3.05   2.54   7.28   2.75   \n",
       "19854  PRECTOTCORR  2022   9.75  82.25   2.33   2.45   2.90   6.28   3.04   \n",
       "\n",
       "         JUN    JUL    AUG    SEP    OCT    NOV    DEC    ANN  \n",
       "0      34.17  27.96  26.88  25.55  24.42  21.24  15.97  25.90  \n",
       "1      34.17  27.91  26.83  25.53  24.12  20.89  15.69  25.75  \n",
       "2      34.49  28.20  27.02  25.76  24.18  20.92  15.70  25.93  \n",
       "3      34.43  28.27  26.99  25.82  24.08  20.87  15.62  25.88  \n",
       "4      34.73  28.65  27.19  25.95  24.17  20.95  15.61  26.00  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "19850   1.78   5.85   3.69   1.81   9.04   9.43   7.85   4.42  \n",
       "19851   1.79   5.52   3.85   2.05   9.13   9.33   8.68   4.59  \n",
       "19852   1.95   5.43   4.11   2.16   8.43   7.85  10.82   4.77  \n",
       "19853   2.31   5.26   4.02   2.19   8.42   5.91  13.61   5.01  \n",
       "19854   2.60   4.73   3.89   2.18   7.99   4.94  14.25   4.83  \n",
       "\n",
       "[359125 rows x 17 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9dbc8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_df CONTAINS COORDINATES AND NOT DISTRICTS. THEREFORE, WE MAP THESE COORDINATES TO THE GROUPED DISTRICTS\n",
    "# WE CREATED IN THE PREVIOUS SECTION.\n",
    "\n",
    "weather_df1 = weather_df.drop_duplicates().reset_index(drop = True)\n",
    "group_gdf = gpd.read_file('latest grouped district boundaries.shp')\n",
    "\n",
    "# maps the coordinates to districts using the intersects method\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(weather_df1['LON'], weather_df1['LAT'])]\n",
    "gdf_weather = gpd.GeoDataFrame(weather_df1, geometry = geometry, crs = group_gdf.crs)\n",
    "gdf_combined = gpd.sjoin(gdf_weather, group_gdf, how = 'right', op = 'intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f9a0274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_left</th>\n",
       "      <th>PARAMETER</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>JAN</th>\n",
       "      <th>FEB</th>\n",
       "      <th>MAR</th>\n",
       "      <th>APR</th>\n",
       "      <th>MAY</th>\n",
       "      <th>...</th>\n",
       "      <th>JUL</th>\n",
       "      <th>AUG</th>\n",
       "      <th>SEP</th>\n",
       "      <th>OCT</th>\n",
       "      <th>NOV</th>\n",
       "      <th>DEC</th>\n",
       "      <th>ANN</th>\n",
       "      <th>grouped_di</th>\n",
       "      <th>state_symb</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28217.0</td>\n",
       "      <td>T2M</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>73.75</td>\n",
       "      <td>22.16</td>\n",
       "      <td>24.05</td>\n",
       "      <td>28.44</td>\n",
       "      <td>30.98</td>\n",
       "      <td>31.65</td>\n",
       "      <td>...</td>\n",
       "      <td>25.69</td>\n",
       "      <td>24.94</td>\n",
       "      <td>24.97</td>\n",
       "      <td>24.47</td>\n",
       "      <td>23.46</td>\n",
       "      <td>19.18</td>\n",
       "      <td>25.66</td>\n",
       "      <td>The Dangs, GJ</td>\n",
       "      <td>GJ</td>\n",
       "      <td>MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28265.0</td>\n",
       "      <td>T2M</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>73.75</td>\n",
       "      <td>20.12</td>\n",
       "      <td>23.66</td>\n",
       "      <td>27.53</td>\n",
       "      <td>30.17</td>\n",
       "      <td>30.26</td>\n",
       "      <td>...</td>\n",
       "      <td>25.46</td>\n",
       "      <td>24.73</td>\n",
       "      <td>24.32</td>\n",
       "      <td>24.35</td>\n",
       "      <td>23.93</td>\n",
       "      <td>23.10</td>\n",
       "      <td>25.48</td>\n",
       "      <td>The Dangs, GJ</td>\n",
       "      <td>GJ</td>\n",
       "      <td>MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28313.0</td>\n",
       "      <td>T2M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>73.75</td>\n",
       "      <td>20.08</td>\n",
       "      <td>23.09</td>\n",
       "      <td>26.30</td>\n",
       "      <td>29.86</td>\n",
       "      <td>29.93</td>\n",
       "      <td>...</td>\n",
       "      <td>25.81</td>\n",
       "      <td>24.90</td>\n",
       "      <td>24.51</td>\n",
       "      <td>25.19</td>\n",
       "      <td>22.62</td>\n",
       "      <td>23.07</td>\n",
       "      <td>25.30</td>\n",
       "      <td>The Dangs, GJ</td>\n",
       "      <td>GJ</td>\n",
       "      <td>MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28361.0</td>\n",
       "      <td>T2M</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>73.75</td>\n",
       "      <td>21.58</td>\n",
       "      <td>23.98</td>\n",
       "      <td>27.11</td>\n",
       "      <td>29.01</td>\n",
       "      <td>30.64</td>\n",
       "      <td>...</td>\n",
       "      <td>24.39</td>\n",
       "      <td>24.10</td>\n",
       "      <td>24.56</td>\n",
       "      <td>23.85</td>\n",
       "      <td>22.18</td>\n",
       "      <td>20.81</td>\n",
       "      <td>24.89</td>\n",
       "      <td>The Dangs, GJ</td>\n",
       "      <td>GJ</td>\n",
       "      <td>MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28409.0</td>\n",
       "      <td>T2M</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>73.75</td>\n",
       "      <td>21.00</td>\n",
       "      <td>22.25</td>\n",
       "      <td>26.43</td>\n",
       "      <td>30.04</td>\n",
       "      <td>30.89</td>\n",
       "      <td>...</td>\n",
       "      <td>26.49</td>\n",
       "      <td>24.91</td>\n",
       "      <td>24.45</td>\n",
       "      <td>24.76</td>\n",
       "      <td>23.89</td>\n",
       "      <td>20.85</td>\n",
       "      <td>25.48</td>\n",
       "      <td>The Dangs, GJ</td>\n",
       "      <td>GJ</td>\n",
       "      <td>MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>27853.0</td>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>20.25</td>\n",
       "      <td>77.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.55</td>\n",
       "      <td>7.91</td>\n",
       "      <td>5.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.64</td>\n",
       "      <td>Yavatmal, MH</td>\n",
       "      <td>MH</td>\n",
       "      <td>POLYGON ((78.27840 20.69391, 78.27733 20.68787...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>27977.0</td>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>19.75</td>\n",
       "      <td>77.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.88</td>\n",
       "      <td>...</td>\n",
       "      <td>10.75</td>\n",
       "      <td>5.65</td>\n",
       "      <td>10.85</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3.27</td>\n",
       "      <td>Yavatmal, MH</td>\n",
       "      <td>MH</td>\n",
       "      <td>POLYGON ((78.27840 20.69391, 78.27733 20.68787...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>27985.0</td>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>20.25</td>\n",
       "      <td>77.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.93</td>\n",
       "      <td>...</td>\n",
       "      <td>9.80</td>\n",
       "      <td>5.65</td>\n",
       "      <td>11.27</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.33</td>\n",
       "      <td>Yavatmal, MH</td>\n",
       "      <td>MH</td>\n",
       "      <td>POLYGON ((78.27840 20.69391, 78.27733 20.68787...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>28109.0</td>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>19.75</td>\n",
       "      <td>77.75</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>22.28</td>\n",
       "      <td>6.19</td>\n",
       "      <td>6.38</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.76</td>\n",
       "      <td>Yavatmal, MH</td>\n",
       "      <td>MH</td>\n",
       "      <td>POLYGON ((78.27840 20.69391, 78.27733 20.68787...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>28117.0</td>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>20.25</td>\n",
       "      <td>77.75</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>20.54</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.58</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.71</td>\n",
       "      <td>Yavatmal, MH</td>\n",
       "      <td>MH</td>\n",
       "      <td>POLYGON ((78.27840 20.69391, 78.27733 20.68787...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70038 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index_left    PARAMETER    YEAR    LAT    LON    JAN    FEB    MAR  \\\n",
       "0       28217.0          T2M  2010.0  20.75  73.75  22.16  24.05  28.44   \n",
       "0       28265.0          T2M  2011.0  20.75  73.75  20.12  23.66  27.53   \n",
       "0       28313.0          T2M  2012.0  20.75  73.75  20.08  23.09  26.30   \n",
       "0       28361.0          T2M  2013.0  20.75  73.75  21.58  23.98  27.11   \n",
       "0       28409.0          T2M  2014.0  20.75  73.75  21.00  22.25  26.43   \n",
       "..          ...          ...     ...    ...    ...    ...    ...    ...   \n",
       "600     27853.0  PRECTOTCORR  2020.0  20.25  77.75   0.00   0.00   0.00   \n",
       "600     27977.0  PRECTOTCORR  2021.0  19.75  77.75   0.00   0.00   0.26   \n",
       "600     27985.0  PRECTOTCORR  2021.0  20.25  77.75   0.00   0.00   0.51   \n",
       "600     28109.0  PRECTOTCORR  2022.0  19.75  77.75   0.97   0.01   0.01   \n",
       "600     28117.0  PRECTOTCORR  2022.0  20.25  77.75   0.89   0.03   0.01   \n",
       "\n",
       "       APR    MAY  ...    JUL    AUG    SEP    OCT    NOV    DEC    ANN  \\\n",
       "0    30.98  31.65  ...  25.69  24.94  24.97  24.47  23.46  19.18  25.66   \n",
       "0    30.17  30.26  ...  25.46  24.73  24.32  24.35  23.93  23.10  25.48   \n",
       "0    29.86  29.93  ...  25.81  24.90  24.51  25.19  22.62  23.07  25.30   \n",
       "0    29.01  30.64  ...  24.39  24.10  24.56  23.85  22.18  20.81  24.89   \n",
       "0    30.04  30.89  ...  26.49  24.91  24.45  24.76  23.89  20.85  25.48   \n",
       "..     ...    ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "600   0.00   0.00  ...  10.55   7.91   5.27   0.00   0.00   0.00   2.64   \n",
       "600   0.20   0.88  ...  10.75   5.65  10.85   2.35   0.17   0.19   3.27   \n",
       "600   0.18   0.93  ...   9.80   5.65  11.27   3.18   0.16   0.27   3.33   \n",
       "600   0.04   0.57  ...  22.28   6.19   6.38   2.52   0.00   0.11   3.76   \n",
       "600   0.03   0.42  ...  20.54   6.90   6.58   2.65   0.00   0.13   3.71   \n",
       "\n",
       "        grouped_di state_symb  \\\n",
       "0    The Dangs, GJ         GJ   \n",
       "0    The Dangs, GJ         GJ   \n",
       "0    The Dangs, GJ         GJ   \n",
       "0    The Dangs, GJ         GJ   \n",
       "0    The Dangs, GJ         GJ   \n",
       "..             ...        ...   \n",
       "600   Yavatmal, MH         MH   \n",
       "600   Yavatmal, MH         MH   \n",
       "600   Yavatmal, MH         MH   \n",
       "600   Yavatmal, MH         MH   \n",
       "600   Yavatmal, MH         MH   \n",
       "\n",
       "                                              geometry  \n",
       "0    MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...  \n",
       "0    MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...  \n",
       "0    MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...  \n",
       "0    MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...  \n",
       "0    MULTIPOLYGON (((73.56427 21.00849, 73.56990 21...  \n",
       "..                                                 ...  \n",
       "600  POLYGON ((78.27840 20.69391, 78.27733 20.68787...  \n",
       "600  POLYGON ((78.27840 20.69391, 78.27733 20.68787...  \n",
       "600  POLYGON ((78.27840 20.69391, 78.27733 20.68787...  \n",
       "600  POLYGON ((78.27840 20.69391, 78.27733 20.68787...  \n",
       "600  POLYGON ((78.27840 20.69391, 78.27733 20.68787...  \n",
       "\n",
       "[70038 rows x 21 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b062698",
   "metadata": {},
   "source": [
    "The resolution of the meteorological variables is very sparse, as the grid is comprised of 0.5 x 0.5 degree squares. The data is present at the corners of these 0.5 x 0.5 degree squares. Due to this sparseness, very small districts end up getting completely skipped out as it is possible that none of the corner points lie within a district's boundaries. In this data, about 90 districts end up getting skipped out. Our strategy to fill the missing data can be summarized in the following steps:\n",
    "1. Establish which districts don't have weather data. In this data, we have 5 weather parameters (temperature, relative humidity, windspeed, dewpoint temperature, precipitation) and any district that doesn't have data for even one parameter doesn't have data for any other parameter either.\n",
    "2. Create empty rows of such districts for each of the 5 parameters so that we can fill them up later on.\n",
    "3. Create a column with the centroid of each of the districts with missing data.\n",
    "4. Of the coordinates which have weather data, see which one is closest to the centroids of such districts (with missing data)\n",
    "5. Fill the missing values with the values from that of the closest points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1017082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS 1,2, AND 3: ADDING EMPTY ROWS SO THAT WE CAN FILL THEM LATER ON USING NEAREST POINT IMPUTATION\n",
    "\n",
    "# DROPPING ROWS WHICH AREN'T REQUIRED, # ANN is annual average for a particular parameter\n",
    "gdf_combined = gdf_combined.drop(columns = ['index_left', 'ANN']) \n",
    "df2 = gdf_combined.copy()\n",
    "df2['centroid'] = df2['geometry'].centroid\n",
    "\n",
    "# adding the null rows corresponding to each parameter and year. 5 parameters, hence 5 different times.\n",
    "to_concat = df2[df2['PARAMETER'].isnull()].copy()\n",
    "to_concat['PARAMETER'] = 'T2M'\n",
    "df2 = pd.concat([to_concat, df2],axis = 0)\n",
    "\n",
    "to_concat = df2[df2['PARAMETER'].isnull()].copy()\n",
    "to_concat['PARAMETER'] = 'RH2M'\n",
    "df2 = pd.concat([to_concat, df2],axis = 0)\n",
    "\n",
    "to_concat = df2[df2['PARAMETER'].isnull()].copy()\n",
    "to_concat['PARAMETER'] = 'WS2M'\n",
    "df2 = pd.concat([to_concat, df2],axis = 0)\n",
    "\n",
    "to_concat = df2[df2['PARAMETER'].isnull()].copy()\n",
    "to_concat['PARAMETER'] = 'T2MDEW'\n",
    "df2 = pd.concat([to_concat, df2],axis = 0)\n",
    "\n",
    "to_concat = df2[df2['PARAMETER'].isnull()].copy()\n",
    "to_concat['PARAMETER'] = 'PRECTOTCORR'\n",
    "df2 = pd.concat([to_concat, df2],axis = 0)\n",
    "\n",
    "df2 = df2[df2['PARAMETER'].isnull() == False].copy() # skips out the rows which we used for replication purposes\n",
    "# above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80475e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN THE PREVIOUS CODE BLOCK, WE CREATE NEW ROWS BASED ON THE DISTRICTS \n",
    "\n",
    "months = df2.columns[4:16]  # gets the list of months\n",
    "parameters = df2['PARAMETER'].unique()  # gets the list of parameters\n",
    "\n",
    "new_df1 = df2[df2['YEAR'].isnull() == False].copy() # skips out the useless rows, which we use to create the\n",
    "# required rows and then add to the main dataframe\n",
    "new_df2 = df2[df2['YEAR'].isnull()].copy() \n",
    "\n",
    "years_range = pd.DataFrame({'YEAR': range(2010, 2023)})\n",
    "\n",
    "to_add = pd.merge(years_range, new_df2, how='cross').drop(columns = ['YEAR_y'])\n",
    "\n",
    "to_add = to_add[['PARAMETER', 'YEAR_x'] + list(to_add.columns[2:])].rename(columns = {'YEAR_x' : 'YEAR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "950f807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOME COLUMN RENAMING OPERATIONS AND THEN, ISOLATING THAT PART OF THE DATAFRAME WHICH NEEDS TO BE FILLED USING\n",
    "# NEAREST POINT MATCHING\n",
    "\n",
    "df3 = pd.concat([new_df1, to_add], axis = 0) # done\n",
    "df3['YEAR'] = df3['YEAR'].astype(int)\n",
    "df3 = df3.reset_index(drop = True)\n",
    "\n",
    "# for districts which don't have points, we assign them the centroid's coordinates, and proceed thereafter.\n",
    "df3['LAT'] = df3['LAT'].fillna(df3['centroid'].apply(lambda point: point.y))\n",
    "df3['LON'] = df3['LON'].fillna(df3['centroid'].apply(lambda point: point.x))\n",
    "\n",
    "df3 = df3.rename(columns = {'state_symb' : 'state', 'grouped_di' : 'district'})\n",
    "df3 = pd.melt(df3, id_vars = ['district', 'state', 'geometry', 'LAT', 'LON', 'centroid', 'PARAMETER', 'YEAR'],\n",
    "       var_name = 'month', value_name = 'measure')\n",
    "\n",
    "new_df = df3.drop(columns = ['geometry', 'centroid']).copy()\n",
    "newer_df = new_df.pivot(index = ['district', 'state', 'LAT', 'LON', 'YEAR', 'month'], columns = 'PARAMETER',\n",
    "            values = 'measure').reset_index()\n",
    "newer_df.columns.name = None\n",
    "filling_df = newer_df.copy()\n",
    "filled_df = filling_df.copy()\n",
    "\n",
    "nulls_df = filled_df[filled_df['T2M'].isnull()] # seperate dataframe of nulls which we will populate with\n",
    "# imputed values\n",
    "nulls_df = nulls_df.reset_index(drop = True)\n",
    "filled_df = filled_df[filled_df['T2M'].isna() == False]\n",
    "full_frame = filling_df[['LAT', 'LON']].drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b63edb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS 4 AND 5\n",
    "coordinates = full_frame[['LAT', 'LON']].values\n",
    "\n",
    "# Create a Nearest Neighbors model\n",
    "k = 2  # Number of neighbors to consider (adjust as needed)\n",
    "nn_model = NearestNeighbors(n_neighbors=k)\n",
    "nn_model.fit(coordinates)\n",
    "\n",
    "search_frame = nulls_df[['LAT', 'LON']].drop_duplicates().reset_index(drop = True)\n",
    "match_values = filled_df[['LAT', 'LON']].drop_duplicates().reset_index(drop = True).values\n",
    "\n",
    "# creating the frames to match on\n",
    "search_frame['LAT_matched'] = np.nan\n",
    "search_frame['LON_matched'] = np.nan\n",
    "\n",
    "for i in range(len(search_frame)):\n",
    "    to_search = nulls_df[['LAT', 'LON']].drop_duplicates().reset_index(drop = True).values[i]\n",
    "    _, indices = nn_model.kneighbors(to_search.reshape(1,-1))\n",
    "    for j in indices[0]:\n",
    "        if full_frame.loc[j].values in match_values:\n",
    "            matched_coord_index = j\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "    search_frame['LAT_matched'][i] = full_frame.loc[matched_coord_index]['LAT']\n",
    "    search_frame['LON_matched'][i] = full_frame.loc[matched_coord_index]['LON']\n",
    "    \n",
    "matched_nulls_df = nulls_df.merge(search_frame, on = ['LAT', 'LON'])\n",
    "matched_nulls_df = matched_nulls_df.rename(columns = {'LAT' : 'LAT_tomatch', 'LON' : 'LON_tomatch',\n",
    "                                                     'LAT_matched' : 'LAT', 'LON_matched' : 'LON'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d28c50b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT_matched</th>\n",
       "      <th>LON_matched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.037660</td>\n",
       "      <td>78.079466</td>\n",
       "      <td>27.25</td>\n",
       "      <td>78.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.423558</td>\n",
       "      <td>76.449580</td>\n",
       "      <td>9.25</td>\n",
       "      <td>76.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.420062</td>\n",
       "      <td>82.668547</td>\n",
       "      <td>26.25</td>\n",
       "      <td>82.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.660686</td>\n",
       "      <td>79.482755</td>\n",
       "      <td>26.75</td>\n",
       "      <td>79.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.890006</td>\n",
       "      <td>74.662969</td>\n",
       "      <td>26.75</td>\n",
       "      <td>79.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>29.027456</td>\n",
       "      <td>79.523466</td>\n",
       "      <td>29.25</td>\n",
       "      <td>79.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>31.580659</td>\n",
       "      <td>76.210080</td>\n",
       "      <td>31.75</td>\n",
       "      <td>76.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>28.655321</td>\n",
       "      <td>77.065700</td>\n",
       "      <td>31.75</td>\n",
       "      <td>76.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>16.726649</td>\n",
       "      <td>82.254560</td>\n",
       "      <td>16.75</td>\n",
       "      <td>82.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>26.031634</td>\n",
       "      <td>94.525282</td>\n",
       "      <td>26.25</td>\n",
       "      <td>94.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          LAT        LON  LAT_matched  LON_matched\n",
       "0   27.037660  78.079466        27.25        78.25\n",
       "1    9.423558  76.449580         9.25        76.75\n",
       "2   26.420062  82.668547        26.25        82.75\n",
       "3   26.660686  79.482755        26.75        79.25\n",
       "4   33.890006  74.662969        26.75        79.25\n",
       "..        ...        ...          ...          ...\n",
       "93  29.027456  79.523466        29.25        79.75\n",
       "94  31.580659  76.210080        31.75        76.25\n",
       "95  28.655321  77.065700        31.75        76.25\n",
       "96  16.726649  82.254560        16.75        82.25\n",
       "97  26.031634  94.525282        26.25        94.75\n",
       "\n",
       "[98 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER RUNNING THE NEAREST NEIGHBOR ALGORITHM, LAT_matched and LON_matched are the points (for which we have data)\n",
    "# which are the closest to the districts' (with missing data) centroids\n",
    "search_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d366e744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>state</th>\n",
       "      <th>LAT_tomatch</th>\n",
       "      <th>LON_tomatch</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>month</th>\n",
       "      <th>PRECTOTCORR</th>\n",
       "      <th>RH2M</th>\n",
       "      <th>T2M</th>\n",
       "      <th>T2MDEW</th>\n",
       "      <th>WS2M</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>27.037660</td>\n",
       "      <td>78.079466</td>\n",
       "      <td>2010</td>\n",
       "      <td>APR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.25</td>\n",
       "      <td>78.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>27.037660</td>\n",
       "      <td>78.079466</td>\n",
       "      <td>2010</td>\n",
       "      <td>AUG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.25</td>\n",
       "      <td>78.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>27.037660</td>\n",
       "      <td>78.079466</td>\n",
       "      <td>2010</td>\n",
       "      <td>DEC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.25</td>\n",
       "      <td>78.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>27.037660</td>\n",
       "      <td>78.079466</td>\n",
       "      <td>2010</td>\n",
       "      <td>FEB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.25</td>\n",
       "      <td>78.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>27.037660</td>\n",
       "      <td>78.079466</td>\n",
       "      <td>2010</td>\n",
       "      <td>JAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.25</td>\n",
       "      <td>78.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15283</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>26.031634</td>\n",
       "      <td>94.525282</td>\n",
       "      <td>2022</td>\n",
       "      <td>MAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.25</td>\n",
       "      <td>94.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15284</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>26.031634</td>\n",
       "      <td>94.525282</td>\n",
       "      <td>2022</td>\n",
       "      <td>MAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.25</td>\n",
       "      <td>94.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15285</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>26.031634</td>\n",
       "      <td>94.525282</td>\n",
       "      <td>2022</td>\n",
       "      <td>NOV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.25</td>\n",
       "      <td>94.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15286</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>26.031634</td>\n",
       "      <td>94.525282</td>\n",
       "      <td>2022</td>\n",
       "      <td>OCT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.25</td>\n",
       "      <td>94.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15287</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>26.031634</td>\n",
       "      <td>94.525282</td>\n",
       "      <td>2022</td>\n",
       "      <td>SEP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.25</td>\n",
       "      <td>94.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15288 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            district state  LAT_tomatch  LON_tomatch  YEAR month  PRECTOTCORR  \\\n",
       "0           Agra, UP    UP    27.037660    78.079466  2010   APR          NaN   \n",
       "1           Agra, UP    UP    27.037660    78.079466  2010   AUG          NaN   \n",
       "2           Agra, UP    UP    27.037660    78.079466  2010   DEC          NaN   \n",
       "3           Agra, UP    UP    27.037660    78.079466  2010   FEB          NaN   \n",
       "4           Agra, UP    UP    27.037660    78.079466  2010   JAN          NaN   \n",
       "...              ...   ...          ...          ...   ...   ...          ...   \n",
       "15283  Zunheboto, NL    NL    26.031634    94.525282  2022   MAR          NaN   \n",
       "15284  Zunheboto, NL    NL    26.031634    94.525282  2022   MAY          NaN   \n",
       "15285  Zunheboto, NL    NL    26.031634    94.525282  2022   NOV          NaN   \n",
       "15286  Zunheboto, NL    NL    26.031634    94.525282  2022   OCT          NaN   \n",
       "15287  Zunheboto, NL    NL    26.031634    94.525282  2022   SEP          NaN   \n",
       "\n",
       "       RH2M  T2M  T2MDEW  WS2M    LAT    LON  \n",
       "0       NaN  NaN     NaN   NaN  27.25  78.25  \n",
       "1       NaN  NaN     NaN   NaN  27.25  78.25  \n",
       "2       NaN  NaN     NaN   NaN  27.25  78.25  \n",
       "3       NaN  NaN     NaN   NaN  27.25  78.25  \n",
       "4       NaN  NaN     NaN   NaN  27.25  78.25  \n",
       "...     ...  ...     ...   ...    ...    ...  \n",
       "15283   NaN  NaN     NaN   NaN  26.25  94.75  \n",
       "15284   NaN  NaN     NaN   NaN  26.25  94.75  \n",
       "15285   NaN  NaN     NaN   NaN  26.25  94.75  \n",
       "15286   NaN  NaN     NaN   NaN  26.25  94.75  \n",
       "15287   NaN  NaN     NaN   NaN  26.25  94.75  \n",
       "\n",
       "[15288 rows x 13 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_nulls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7863317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FURTHER FORMATTING AND RENAMING COLUMNS AND VALUES FOR MERGING LATER WITH THE OTHER (VEHICLE REGISTRATIONS,\n",
    "# PM2.5, NIGHTLIGHT DATA) DATAFRAMES\n",
    "matched_nulls_df2 = matched_nulls_df.merge(filled_df, on = ['LAT', 'LON', 'YEAR', 'month'], how = 'inner')\n",
    "\n",
    "for i in range(len(matched_nulls_df2)):\n",
    "    matched_nulls_df2['PRECTOTCORR_x'][i] = matched_nulls_df2['PRECTOTCORR_y'][i]\n",
    "    matched_nulls_df2['RH2M_x'][i] = matched_nulls_df2['RH2M_y'][i]\n",
    "    matched_nulls_df2['T2M_x'][i] = matched_nulls_df2['T2M_y'][i]\n",
    "    matched_nulls_df2['T2MDEW_x'][i] = matched_nulls_df2['T2MDEW_y'][i]\n",
    "    matched_nulls_df2['WS2M_x'][i] = matched_nulls_df2['WS2M_y'][i]\n",
    "\n",
    "matched_nulls_df2 = matched_nulls_df2[['district_x', 'state_x', 'LAT_tomatch', 'LON_tomatch', 'YEAR', 'month', \n",
    "         'PRECTOTCORR_x', 'RH2M_x', 'T2M_x', 'T2MDEW_x', 'WS2M_x']]\n",
    "matched_nulls_df2 = matched_nulls_df2.rename(columns = {'district_x' : 'district', 'state_x' : 'state', 'LAT_tomatch' : 'LAT',\n",
    "                                     'LON_tomatch' : 'LON', 'PRECTOTCORR_x' : 'PRECTOTCORR', 'RH2M_x' : 'RH2M',\n",
    "                                     'T2M_x' : 'T2M', 'T2MDEW_x' : 'T2MDEW', 'WS2M_x' : 'WS2M'})\n",
    "\n",
    "updated_filled_df = pd.concat([filled_df, matched_nulls_df2]).reset_index(drop = True)\n",
    "\n",
    "month_mapping = {'JAN' : 1, 'FEB' : 2, 'MAR' : 3, 'APR' : 4, 'MAY' : 5, 'JUN' : 6, 'JUL' : 7,\n",
    "              'AUG' : 8, 'SEP' : 9, 'OCT' : 10, 'NOV' : 11, 'DEC' : 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "584da202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map month initials to month numbers\n",
    "def map_month_initials(month_initial):\n",
    "    return month_mapping.get(month_initial.upper(), None)\n",
    "\n",
    "# Apply the mapping function to create a new column with month numbers\n",
    "updated_filled_df['month'] = updated_filled_df['month'].apply(map_month_initials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "314c718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_filled_df['YEAR'] = updated_filled_df['YEAR'].astype(str)\n",
    "updated_filled_df['month'] = updated_filled_df['month'].astype(str)\n",
    "updated_filled_df['year_month'] = updated_filled_df['YEAR'] + '-' + updated_filled_df['month']\n",
    "updated_filled_df['year_month'] = pd.to_datetime(updated_filled_df['year_month'])\n",
    "updated_filled_df = updated_filled_df.drop(columns = ['YEAR', 'month'])\n",
    "\n",
    "updated_filled_df = updated_filled_df.groupby(by = ['district', 'state', 'year_month']).agg({'PRECTOTCORR' : 'mean',\n",
    "                                                                       'RH2M' : 'mean',\n",
    "                                                                       'T2M' : 'mean',\n",
    "                                                                       'T2MDEW' : 'mean',\n",
    "                                                                       'WS2M' : 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0db7e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>state</th>\n",
       "      <th>year_month</th>\n",
       "      <th>PRECTOTCORR</th>\n",
       "      <th>RH2M</th>\n",
       "      <th>T2M</th>\n",
       "      <th>T2MDEW</th>\n",
       "      <th>WS2M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.34</td>\n",
       "      <td>15.10</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>19.10</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.96</td>\n",
       "      <td>27.27</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.12</td>\n",
       "      <td>33.74</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>2010-05-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.39</td>\n",
       "      <td>37.19</td>\n",
       "      <td>6.08</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93751</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>6.23</td>\n",
       "      <td>82.38</td>\n",
       "      <td>24.82</td>\n",
       "      <td>21.16</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93752</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>7.40</td>\n",
       "      <td>84.57</td>\n",
       "      <td>23.69</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93753</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>6.44</td>\n",
       "      <td>81.52</td>\n",
       "      <td>20.98</td>\n",
       "      <td>17.31</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93754</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.72</td>\n",
       "      <td>16.85</td>\n",
       "      <td>11.51</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93755</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>0.47</td>\n",
       "      <td>77.26</td>\n",
       "      <td>13.80</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93756 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            district state year_month  PRECTOTCORR   RH2M    T2M  T2MDEW  WS2M\n",
       "0           Agra, UP    UP 2010-01-01         0.00  43.34  15.10    1.57  1.28\n",
       "1           Agra, UP    UP 2010-02-01         0.00  42.14  19.10    4.35  1.54\n",
       "2           Agra, UP    UP 2010-03-01         0.00  21.96  27.27    1.63  1.92\n",
       "3           Agra, UP    UP 2010-04-01         0.00  13.12  33.74    0.49  2.34\n",
       "4           Agra, UP    UP 2010-05-01         0.00  16.39  37.19    6.08  2.23\n",
       "...              ...   ...        ...          ...    ...    ...     ...   ...\n",
       "93751  Zunheboto, NL    NL 2022-08-01         6.23  82.38  24.82   21.16  0.18\n",
       "93752  Zunheboto, NL    NL 2022-09-01         7.40  84.57  23.69   20.60  0.22\n",
       "93753  Zunheboto, NL    NL 2022-10-01         6.44  81.52  20.98   17.31  0.29\n",
       "93754  Zunheboto, NL    NL 2022-11-01         0.00  72.72  16.85   11.51  0.42\n",
       "93755  Zunheboto, NL    NL 2022-12-01         0.47  77.26  13.80    9.50  0.43\n",
       "\n",
       "[93756 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_dataset = updated_filled_df.copy()\n",
    "weather_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8a309e",
   "metadata": {},
   "source": [
    "# Section 4: Urban PM2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ca0043",
   "metadata": {},
   "source": [
    "Electric vehicles are specifically promoted for urban areas, and therefore, it makes sense to measure its impact on urban pollution specifically. NASA classified localities in India into 5 classes of urbanness, based on GHSL. These classes are:\n",
    "1. BUILT UP LAND ONLY\n",
    "2. RURAL\n",
    "3. UNINHABITED\n",
    "4. AGGREMENT\n",
    "5. URBAN PEOPLE ONLY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dc8ed2",
   "metadata": {},
   "source": [
    "To isolate urban areas out of these 5 classes, we focus only on 1,4, and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0da97ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUILT-UP LAND ONLY</td>\n",
       "      <td>MULTIPOLYGON (((93.92332 6.96365, 93.92307 6.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RURAL</td>\n",
       "      <td>MULTIPOLYGON (((93.67074 7.00203, 93.67039 7.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNINHABITED</td>\n",
       "      <td>MULTIPOLYGON (((77.07998 8.60055, 77.08056 8.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URBAN AGGREMENT</td>\n",
       "      <td>MULTIPOLYGON (((77.55156 8.08249, 77.55105 8.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URBAN PEOPLE ONLY</td>\n",
       "      <td>MULTIPOLYGON (((77.55041 8.07335, 77.55029 8.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CLASS                                           geometry\n",
       "0  BUILT-UP LAND ONLY  MULTIPOLYGON (((93.92332 6.96365, 93.92307 6.9...\n",
       "1               RURAL  MULTIPOLYGON (((93.67074 7.00203, 93.67039 7.0...\n",
       "2         UNINHABITED  MULTIPOLYGON (((77.07998 8.60055, 77.08056 8.6...\n",
       "3     URBAN AGGREMENT  MULTIPOLYGON (((77.55156 8.08249, 77.55105 8.0...\n",
       "4   URBAN PEOPLE ONLY  MULTIPOLYGON (((77.55041 8.07335, 77.55029 8.0..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_files = zf.ZipFile('India urbanness shapefile Columbia.zip', 'r')\n",
    "urban_files.extractall('India urbanness shapefiles')\n",
    "\n",
    "file_location = 'India urbanness shapefiles/india-spatial-india-census-2011-census-ghsl-50pct-shp/india-spatial-india-census-2011_census-ghsl-50pct-india.shp'\n",
    "gdf_urban = gpd.read_file(file_location)\n",
    "gdf_urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6e83301",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_drop = [1, 2]\n",
    "\n",
    "# dropping the rural and uninhabited columns as they are redundant once we have the urban areas, and also\n",
    "# we only require their PM2.5 levels for the pollution measure.\n",
    "gdf_urban = gdf_urban.drop(index = rows_to_drop)\n",
    "\n",
    "urban1 = gpd.overlay(grouped_district_boundaries, gdf_urban.tail(2).head(1), how = 'intersection')\n",
    "urban1.to_file('urban1.shp')\n",
    "\n",
    "urban2 = gpd.overlay(grouped_district_boundaries, gdf_urban.tail(1), how = 'intersection')\n",
    "urban2.to_file('urban2.shp')\n",
    "\n",
    "urban3 = gpd.overlay(grouped_district_boundaries, gdf_urban.head(1), how = 'intersection')\n",
    "urban3.to_file('urban3.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "610d6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urbans = gpd.GeoDataFrame(pd.concat([urban1, urban2, urban3], ignore_index = True, axis = 0))\n",
    "\n",
    "all_urbans = all_urbans.groupby(['grouped_district', 'state_symbol'])['geometry'].apply(lambda x: x.unary_union).reset_index()\n",
    "\n",
    "all_urbans.to_file('district urban area shapefiles.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "643fc78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grouped_district</th>\n",
       "      <th>state_symbol</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>MULTIPOLYGON (((77.59715 26.86008, 77.59402 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmadabad + Bhavnagar, GJ</td>\n",
       "      <td>GJ</td>\n",
       "      <td>MULTIPOLYGON (((71.82320 21.06875, 71.82327 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmadnagar, MH</td>\n",
       "      <td>MH</td>\n",
       "      <td>MULTIPOLYGON (((74.39797 18.82109, 74.39537 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aizawl, MZ</td>\n",
       "      <td>MZ</td>\n",
       "      <td>MULTIPOLYGON (((92.72666 23.62267, 92.72690 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ajmer, RJ</td>\n",
       "      <td>RJ</td>\n",
       "      <td>MULTIPOLYGON (((74.02664 25.74706, 74.03096 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Yadgir, KA</td>\n",
       "      <td>KA</td>\n",
       "      <td>MULTIPOLYGON (((76.40124 16.35453, 76.40340 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Yamunanagar, HR</td>\n",
       "      <td>HR</td>\n",
       "      <td>MULTIPOLYGON (((77.20559 29.96045, 77.20487 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Yanam, PY</td>\n",
       "      <td>PY</td>\n",
       "      <td>MULTIPOLYGON (((82.21459 16.71944, 82.21471 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Yavatmal, MH</td>\n",
       "      <td>MH</td>\n",
       "      <td>MULTIPOLYGON (((77.80274 19.46673, 77.80061 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>MULTIPOLYGON (((94.45886 25.94251, 94.46054 25...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              grouped_district state_symbol  \\\n",
       "0                     Agra, UP           UP   \n",
       "1    Ahmadabad + Bhavnagar, GJ           GJ   \n",
       "2               Ahmadnagar, MH           MH   \n",
       "3                   Aizawl, MZ           MZ   \n",
       "4                    Ajmer, RJ           RJ   \n",
       "..                         ...          ...   \n",
       "593                 Yadgir, KA           KA   \n",
       "594            Yamunanagar, HR           HR   \n",
       "595                  Yanam, PY           PY   \n",
       "596               Yavatmal, MH           MH   \n",
       "597              Zunheboto, NL           NL   \n",
       "\n",
       "                                              geometry  \n",
       "0    MULTIPOLYGON (((77.59715 26.86008, 77.59402 26...  \n",
       "1    MULTIPOLYGON (((71.82320 21.06875, 71.82327 21...  \n",
       "2    MULTIPOLYGON (((74.39797 18.82109, 74.39537 18...  \n",
       "3    MULTIPOLYGON (((92.72666 23.62267, 92.72690 23...  \n",
       "4    MULTIPOLYGON (((74.02664 25.74706, 74.03096 25...  \n",
       "..                                                 ...  \n",
       "593  MULTIPOLYGON (((76.40124 16.35453, 76.40340 16...  \n",
       "594  MULTIPOLYGON (((77.20559 29.96045, 77.20487 29...  \n",
       "595  MULTIPOLYGON (((82.21459 16.71944, 82.21471 16...  \n",
       "596  MULTIPOLYGON (((77.80274 19.46673, 77.80061 19...  \n",
       "597  MULTIPOLYGON (((94.45886 25.94251, 94.46054 25...  \n",
       "\n",
       "[598 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_urbans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf710482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE PM2.5 DATA FILES FROM WUSTL CONTAIN DATA FOR ALL COORDINATES WITHIN ASIA. THIS CODE BLOCK ISOLATES THAT TO\n",
    "# JUST COORDINATES BELONGING TO INDIA. GIVEN THAT THE FILES CONTAINS MILLIONS OF POINTS, IT BECOMES IMPORTANT TO\n",
    "# ISOLATE IT JUST TO INDIA FOR COMPUTATIONAL SPEED. ALL THE MONTHLY FILES ARE APPENDED TO THE LIST overall_pm25\n",
    "\n",
    "directory = 'higher resolution PM2.5 data monthly files/'\n",
    "files_list = os.listdir(directory)\n",
    "files_list.sort()\n",
    "\n",
    "pollution_df_file = files_list[27] # starting from april 2012\n",
    "\n",
    "data = Dataset(directory + pollution_df_file)\n",
    "\n",
    "lon_data = data.variables['lon'][:]\n",
    "lat_data = data.variables['lat'][:]\n",
    "pm25_data = data.variables['GWRPM25']\n",
    "\n",
    "lon_data = [ round(lon, 4) for lon in lon_data ]\n",
    "lat_data = [ round(lat, 4) for lat in lat_data ]\n",
    "\n",
    "india_lat = []\n",
    "india_lon = []\n",
    "for lon in lon_data:\n",
    "    if int(lon) in range(68,98):\n",
    "        india_lon.append(lon)\n",
    "\n",
    "for lat in lat_data:\n",
    "    if int(lat) in range(8, 38):\n",
    "        india_lat.append(lat)\n",
    "\n",
    "pollution_df = xr.open_dataset(directory + pollution_df_file)\n",
    "pollution_df = pollution_df.to_dataframe()\n",
    "pollution_df = pollution_df.reset_index()\n",
    "pollution_df['lon'] = pollution_df['lon'].round(4)\n",
    "pollution_df['lat'] = pollution_df['lat'].round(4)\n",
    "pollution_df = pollution_df[(pollution_df['lat'] >= india_lat[0]) & (pollution_df['lat'] <= india_lat[-1])\n",
    "                & (pollution_df['lon'] >= india_lon[0]) & (pollution_df['lon'] <= india_lon[-1])]\n",
    "\n",
    "time_period = pollution_df_file.split('.')[3].split('-')[0]\n",
    "pollution_df = pollution_df.rename(columns = {'GWRPM25' : time_period})\n",
    "\n",
    "overall_pm25 = [pollution_df]\n",
    "\n",
    "for file in files_list[28:]: # continuing from may 2012\n",
    "    month_pollution_df = xr.open_dataset(directory + file)\n",
    "    month_pollution_df = month_pollution_df.to_dataframe()\n",
    "    month_pollution_df = month_pollution_df.reset_index()\n",
    "    month_pollution_df['lon'] = month_pollution_df['lon'].round(4)\n",
    "    month_pollution_df['lat'] = month_pollution_df['lat'].round(4)\n",
    "    month_pollution_df = month_pollution_df[(month_pollution_df['lat'] >= india_lat[0]) & (month_pollution_df['lat'] <= india_lat[-1])\n",
    "                    & (month_pollution_df['lon'] >= india_lon[0]) & (month_pollution_df['lon'] <= india_lon[-1])]\n",
    "    \n",
    "    time_period = file.split('.')[3].split('-')[0]\n",
    "    month_pollution_df = month_pollution_df.rename(columns = {'lon' : 'lon_' + time_period, 'lat' : 'lat_' + time_period,\n",
    "                           'GWRPM25' : time_period})\n",
    "    overall_pm25.append(month_pollution_df[time_period])\n",
    "    \n",
    "    #print(str(files_list.index(file)) + ' ' + time_period + ' done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67bdbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERTICALLY APPENDING ALL THE FILES PRESENT IN overall_pm25\n",
    "merged_pollution_df = pd.concat(overall_pm25, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d382a791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>201204</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>grouped_district</th>\n",
       "      <th>state_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2043842</th>\n",
       "      <td>68.715</td>\n",
       "      <td>23.425</td>\n",
       "      <td>47.900002</td>\n",
       "      <td>POINT (68.71500 23.42500)</td>\n",
       "      <td>257</td>\n",
       "      <td>Kachchh ^, GJ</td>\n",
       "      <td>GJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346335</th>\n",
       "      <td>69.265</td>\n",
       "      <td>23.355</td>\n",
       "      <td>41.700001</td>\n",
       "      <td>POINT (69.26500 23.35500)</td>\n",
       "      <td>257</td>\n",
       "      <td>Kachchh ^, GJ</td>\n",
       "      <td>GJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384784</th>\n",
       "      <td>69.335</td>\n",
       "      <td>22.845</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>POINT (69.33500 22.84500)</td>\n",
       "      <td>257</td>\n",
       "      <td>Kachchh ^, GJ</td>\n",
       "      <td>GJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390282</th>\n",
       "      <td>69.345</td>\n",
       "      <td>22.825</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>POINT (69.34500 22.82500)</td>\n",
       "      <td>257</td>\n",
       "      <td>Kachchh ^, GJ</td>\n",
       "      <td>GJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390283</th>\n",
       "      <td>69.345</td>\n",
       "      <td>22.835</td>\n",
       "      <td>45.400002</td>\n",
       "      <td>POINT (69.34500 22.83500)</td>\n",
       "      <td>257</td>\n",
       "      <td>Kachchh ^, GJ</td>\n",
       "      <td>GJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17510291</th>\n",
       "      <td>96.835</td>\n",
       "      <td>27.915</td>\n",
       "      <td>18.200001</td>\n",
       "      <td>POINT (96.83500 27.91500)</td>\n",
       "      <td>20</td>\n",
       "      <td>Anjaw, AR</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17510292</th>\n",
       "      <td>96.835</td>\n",
       "      <td>27.925</td>\n",
       "      <td>18.200001</td>\n",
       "      <td>POINT (96.83500 27.92500)</td>\n",
       "      <td>20</td>\n",
       "      <td>Anjaw, AR</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17510293</th>\n",
       "      <td>96.835</td>\n",
       "      <td>27.935</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>POINT (96.83500 27.93500)</td>\n",
       "      <td>20</td>\n",
       "      <td>Anjaw, AR</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17510294</th>\n",
       "      <td>96.835</td>\n",
       "      <td>27.945</td>\n",
       "      <td>18.200001</td>\n",
       "      <td>POINT (96.83500 27.94500)</td>\n",
       "      <td>20</td>\n",
       "      <td>Anjaw, AR</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17515793</th>\n",
       "      <td>96.845</td>\n",
       "      <td>27.935</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>POINT (96.84500 27.93500)</td>\n",
       "      <td>20</td>\n",
       "      <td>Anjaw, AR</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95168 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon     lat     201204                   geometry  index_right  \\\n",
       "2043842   68.715  23.425  47.900002  POINT (68.71500 23.42500)          257   \n",
       "2346335   69.265  23.355  41.700001  POINT (69.26500 23.35500)          257   \n",
       "2384784   69.335  22.845  43.500000  POINT (69.33500 22.84500)          257   \n",
       "2390282   69.345  22.825  46.799999  POINT (69.34500 22.82500)          257   \n",
       "2390283   69.345  22.835  45.400002  POINT (69.34500 22.83500)          257   \n",
       "...          ...     ...        ...                        ...          ...   \n",
       "17510291  96.835  27.915  18.200001  POINT (96.83500 27.91500)           20   \n",
       "17510292  96.835  27.925  18.200001  POINT (96.83500 27.92500)           20   \n",
       "17510293  96.835  27.935  18.100000  POINT (96.83500 27.93500)           20   \n",
       "17510294  96.835  27.945  18.200001  POINT (96.83500 27.94500)           20   \n",
       "17515793  96.845  27.935  18.100000  POINT (96.84500 27.93500)           20   \n",
       "\n",
       "         grouped_district state_symbol  \n",
       "2043842     Kachchh ^, GJ           GJ  \n",
       "2346335     Kachchh ^, GJ           GJ  \n",
       "2384784     Kachchh ^, GJ           GJ  \n",
       "2390282     Kachchh ^, GJ           GJ  \n",
       "2390283     Kachchh ^, GJ           GJ  \n",
       "...                   ...          ...  \n",
       "17510291        Anjaw, AR           AR  \n",
       "17510292        Anjaw, AR           AR  \n",
       "17510293        Anjaw, AR           AR  \n",
       "17510294        Anjaw, AR           AR  \n",
       "17515793        Anjaw, AR           AR  \n",
       "\n",
       "[95168 rows x 7 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fff777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPPING THE PM2.5 DATA (WHICH IS FOR COORDINATES AND NOT DISTRICTS DIRECTLY) TO THE GROUPED DISTRICT SHAPEFILES\n",
    "spatial_df = merged_pollution_df.iloc[:, :3]\n",
    "spatial_df['lat'] = spatial_df['lat'].astype(float)\n",
    "spatial_df['lon'] = spatial_df['lon'].astype(float)\n",
    "\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(spatial_df['lon'], spatial_df['lat'])]\n",
    "print('geometry created')\n",
    "gdf_ntl = gpd.GeoDataFrame(spatial_df, geometry = geometry, crs = all_urbans.crs)\n",
    "print('dataframe created')\n",
    "gdf_combined = gpd.sjoin(gdf_ntl, all_urbans, how = 'inner', predicate = 'intersects')\n",
    "print('sjoin done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5cd8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_locations = gdf_combined.copy().rename(columns = {'grouped_district' : 'district'}) # gives you the location reference for each point in the cities\n",
    "urbans_df = merged_pollution_df.loc[gdf_locations.index]\n",
    "gdf_locations = gdf_locations.dropna()[['lon', 'lat', 'district']]\n",
    "urbans_df['lat'] = urbans_df['lat'].astype(float)\n",
    "urbans_df['lon'] = urbans_df['lon'].astype(float)\n",
    "urbans_df = urbans_df.merge(gdf_locations, on = ['lon', 'lat'])\n",
    "\n",
    "urbans_data = pd.melt(urbans_df, id_vars=['lon',\n",
    "                                          'lat', 'district'], var_name = 'year_month', value_name = 'GWRPM25')\n",
    "urbans_data = urbans_data[['district', 'year_month', 'GWRPM25']]\n",
    "urbans_data['year_month'] = urbans_data['year_month'].apply(lambda x: str(x[:4]) + '-' + str(x[4:]))\n",
    "urbans_data['year_month'] = pd.to_datetime(urbans_data['year_month'])\n",
    "urbans_data = urbans_data.groupby(by = ['district', 'year_month'])['GWRPM25'].mean().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f884931a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>year_month</th>\n",
       "      <th>GWRPM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>79.480270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-05-01</td>\n",
       "      <td>77.330040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>60.452469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>56.436771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>49.920628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77008</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>16.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77009</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>19.314285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77010</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>16.542858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77011</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77012</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>12.171428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77013 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            district year_month    GWRPM25\n",
       "0           Agra, UP 2012-04-01  79.480270\n",
       "1           Agra, UP 2012-05-01  77.330040\n",
       "2           Agra, UP 2012-06-01  60.452469\n",
       "3           Agra, UP 2012-07-01  56.436771\n",
       "4           Agra, UP 2012-08-01  49.920628\n",
       "...              ...        ...        ...\n",
       "77008  Zunheboto, NL 2022-08-01  16.142857\n",
       "77009  Zunheboto, NL 2022-09-01  19.314285\n",
       "77010  Zunheboto, NL 2022-10-01  16.542858\n",
       "77011  Zunheboto, NL 2022-11-01   2.514286\n",
       "77012  Zunheboto, NL 2022-12-01  12.171428\n",
       "\n",
       "[77013 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_pm25_dataset = urbans_data.copy()\n",
    "urban_pm25_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056fc826",
   "metadata": {},
   "source": [
    "# Section 5: Urban nightlight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435c35f",
   "metadata": {},
   "source": [
    "When downloaded, the nightlight images are 2GB in size (for each month). to reduce this to a manageable size, we write the below nightlight_data function to accomplish two things mainly:\n",
    "1. To restrict the image's data to India's boundaries. While the 2GB files contain information on all of Asia, this is unnecessary.\n",
    "2. To upscale/downscale the resolution of the pictures. When I upload the images on dropbox, this function helps me reduce the 2GB images to roughly 3 MB each. However, at that level, the resolution is too low to have enough data to map to the districts. Therefore, once the image has been downloaded from dropbox to your system, the below function upscales these images by a factor of 10 (on each dimension) to arrive at 300MB image files. This level is ideal for the level of my units (i.e. districts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "108bdfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_element(lst, target):\n",
    "    return min(lst, key = lambda x: abs(x - target))\n",
    "\n",
    "def nightlight_data(tif_file_path, upscale_factor):\n",
    "    \n",
    "    with rasterio.open(tif_file_path) as dataset:\n",
    "        # Resample data to target shape\n",
    "        data = dataset.read(\n",
    "            out_shape=(\n",
    "                dataset.count,\n",
    "                int(dataset.height * upscale_factor),\n",
    "                int(dataset.width * upscale_factor)\n",
    "            ),\n",
    "            resampling=Resampling.average\n",
    "        )\n",
    "\n",
    "        # Scale image transform\n",
    "        transform = dataset.transform * dataset.transform.scale(\n",
    "            (dataset.width / data.shape[-1]),\n",
    "            (dataset.height / data.shape[-2])\n",
    "        )\n",
    "\n",
    "        # Create a new GeoTIFF file for the resampled data\n",
    "        output_file = tif_file_path\n",
    "        with rasterio.open(output_file, 'w', driver='GTiff', height=data.shape[-2], width=data.shape[-1], count=dataset.count, dtype=data.dtype, crs=dataset.crs, transform=transform) as dst:\n",
    "            dst.write(data)\n",
    "\n",
    "    tif_file_path = output_file\n",
    "    dataarray = rxr.open_rasterio(tif_file_path)\n",
    "    dataarray = xr.open_rasterio(tif_file_path)\n",
    "\n",
    "    ntl_df = dataarray[0].to_pandas()\n",
    "\n",
    "    lonlist = list(ntl_df.columns)\n",
    "    latlist = list(ntl_df.index)\n",
    "\n",
    "    lon_lower = str(find_closest_element(lonlist, 68))\n",
    "    lon_upper = str(find_closest_element(lonlist, 98))\n",
    "\n",
    "    lat_lower = str(find_closest_element(latlist, 8))\n",
    "    lat_upper = str(find_closest_element(latlist, 38))\n",
    "\n",
    "    ntl_df.columns = ntl_df.columns.astype(str)\n",
    "    ntl_df.index = ntl_df.index.astype(str)\n",
    "\n",
    "    lon_lower_index = ntl_df.columns.get_loc(lon_lower)\n",
    "    lon_upper_index = ntl_df.columns.get_loc(lon_upper)\n",
    "\n",
    "    lat_lower_index = ntl_df.index.get_loc(lat_lower)\n",
    "    lat_upper_index = ntl_df.index.get_loc(lat_upper)\n",
    "\n",
    "    ntl_df = ntl_df.iloc[:, lon_lower_index : lon_upper_index + 1]\n",
    "    ntl_df = ntl_df.iloc[lat_upper_index : lat_lower_index + 1, :]\n",
    "\n",
    "    exp_ntl_df = ntl_df.reset_index()\n",
    "    exp_ntl_df = exp_ntl_df.rename(columns = {'y' : 'lat'})\n",
    "    to_melt_list = list(exp_ntl_df.columns[1:])\n",
    "    exp_ntl_df = pd.melt(exp_ntl_df, id_vars = ['lat'], value_vars = to_melt_list).rename(columns = {'x' : 'lon',\n",
    "                                                                                            'value' : 'nightlight'})\n",
    "    \n",
    "    year_month = tif_file_path.split('-')[0].split('_')[-1][:6]\n",
    "    exp_ntl_df = exp_ntl_df.rename(columns = {'lat' : 'lat_' + year_month,\n",
    "                                      'lon' : 'lon_' + year_month,\n",
    "                                     'nightlight' : year_month})\n",
    "    #exp_ntl_df.to_csv('nightlight_data - ' + exp_ntl_df['year_month'][0] + '.csv')\n",
    "    return (exp_ntl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE CODE READS AND APPENDS EACH MONTH'S NIGHTLIGHT DATA TO NTL_DF_LIST. COMBINED_DF APPENDS ALL THE NIGHTLIGHT\n",
    "# DATA FROM NTL_DF_LIST\n",
    "\n",
    "files_list = os.listdir('Monthly nightlight data (all years)')\n",
    "files_list.sort()\n",
    "\n",
    "df_file = files_list[0] # starting from april 2012\n",
    "directory = 'Monthly nightlight data (all years)/'\n",
    "\n",
    "main_df_file = directory + df_file\n",
    "main_df = nightlight_data(main_df_file, 10)\n",
    "\n",
    "ntl_df_list = [main_df]\n",
    "for i in files_list[1:]:\n",
    "    month_df_file = directory + i\n",
    "    data_column = i.split('-')[0].split('_')[-1][:6]\n",
    "    month_df = nightlight_data(month_df_file, 10) \n",
    "    ntl_df_list.append(month_df[data_column])\n",
    "\n",
    "combined_df = pd.concat(ntl_df_list, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "badeb17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geometry created\n",
      "dataframe created\n",
      "sjoin done\n"
     ]
    }
   ],
   "source": [
    "# MAPS THE COORDINATES TO THE DISTRICTS, AS IN THE PREVIOUS CASE.\n",
    "spatial_df = combined_df.iloc[:, :3]\n",
    "spatial_df = spatial_df.rename(columns = {'lat_202208' : 'lat', 'lon_202208' : 'lon'})\n",
    "spatial_df['lat'] = spatial_df['lat'].astype(float)\n",
    "spatial_df['lon'] = spatial_df['lon'].astype(float)\n",
    "\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(spatial_df['lon'], spatial_df['lat'])]\n",
    "print('geometry created')\n",
    "gdf_ntl = gpd.GeoDataFrame(spatial_df, geometry = geometry, crs = all_urbans.crs)\n",
    "print('dataframe created')\n",
    "gdf_combined = gpd.sjoin(gdf_ntl, all_urbans, how = 'inner', predicate = 'intersects')\n",
    "print('sjoin done')\n",
    "\n",
    "\n",
    "gdf_locations = gdf_combined.copy().rename(columns = {'grouped_district' : 'district'}) # gives you the location reference for each point in the cities\n",
    "urban_ntl_df = combined_df.loc[gdf_locations.index]\n",
    "gdf_locations = gdf_locations.dropna()[['lon', 'lat', 'district']]\n",
    "urban_ntl_df = urban_ntl_df.rename(columns = {'lat_202208' : 'lat', 'lon_202208' : 'lon'})\n",
    "urban_ntl_df['lat'] = urban_ntl_df['lat'].astype(float)\n",
    "urban_ntl_df['lon'] = urban_ntl_df['lon'].astype(float)\n",
    "urban_ntl_df = urban_ntl_df.merge(gdf_locations, on = ['lon', 'lat'])\n",
    "\n",
    "urban_ntl_data = pd.melt(urban_ntl_df, id_vars=['lon',\n",
    "                                          'lat', 'district'], var_name = 'year_month', value_name = 'nightlight')\n",
    "urban_ntl_data = urban_ntl_data[['district', 'year_month', 'nightlight']]\n",
    "urban_ntl_data['year_month'] = urban_ntl_data['year_month'].apply(lambda x: str(x[:4]) + '-' + str(x[4:]))\n",
    "urban_ntl_data['year_month'] = pd.to_datetime(urban_ntl_data['year_month'])\n",
    "urban_ntl_data = urban_ntl_data.groupby(by = ['district', 'year_month'])['nightlight'].mean().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b6e669f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>year_month</th>\n",
       "      <th>nightlight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>11.859727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-05-01</td>\n",
       "      <td>5.769569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>7.382822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.066151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>2.599350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77008</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>0.624973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77009</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>0.639530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77010</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>0.579095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77011</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>0.622628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77012</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>0.682471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77013 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            district year_month  nightlight\n",
       "0           Agra, UP 2012-04-01   11.859727\n",
       "1           Agra, UP 2012-05-01    5.769569\n",
       "2           Agra, UP 2012-06-01    7.382822\n",
       "3           Agra, UP 2012-07-01    0.066151\n",
       "4           Agra, UP 2012-08-01    2.599350\n",
       "...              ...        ...         ...\n",
       "77008  Zunheboto, NL 2022-08-01    0.624973\n",
       "77009  Zunheboto, NL 2022-09-01    0.639530\n",
       "77010  Zunheboto, NL 2022-10-01    0.579095\n",
       "77011  Zunheboto, NL 2022-11-01    0.622628\n",
       "77012  Zunheboto, NL 2022-12-01    0.682471\n",
       "\n",
       "[77013 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_ntl_dataset = urban_ntl_data.copy()\n",
    "urban_ntl_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3861751",
   "metadata": {},
   "source": [
    "# Section 6: Merging the created datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a88387",
   "metadata": {},
   "source": [
    "Based on grouped_district_boundaries, we merge the following 4 datasets:\n",
    "1. registrations_dataset\n",
    "2. weather_dataset\n",
    "3. urban_pm25_dataset\n",
    "4. urban_ntl_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2af7f",
   "metadata": {},
   "source": [
    "We merge the attributes from each of the datasets on the district and year-month column. Since the naming of attributes is different only in registrations_dataset and same in the others, we make the following modifications to registrations_dataset:\n",
    "1. rename grouped_district to district\n",
    "2. bring year and month together into a column called year_month, with the same format as the other datasets (using month_mapping, created towards the end of section 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fd1a6181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grouped_district</th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>state_symbol</th>\n",
       "      <th>month</th>\n",
       "      <th>overall_count</th>\n",
       "      <th>ev_count</th>\n",
       "      <th>ev_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2010</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>UP</td>\n",
       "      <td>APR</td>\n",
       "      <td>2165</td>\n",
       "      <td>2</td>\n",
       "      <td>0.092379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2010</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>UP</td>\n",
       "      <td>AUG</td>\n",
       "      <td>4212</td>\n",
       "      <td>5</td>\n",
       "      <td>0.118708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2010</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>UP</td>\n",
       "      <td>DEC</td>\n",
       "      <td>4943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2010</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>UP</td>\n",
       "      <td>FEB</td>\n",
       "      <td>3667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2010</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>UP</td>\n",
       "      <td>JAN</td>\n",
       "      <td>5247</td>\n",
       "      <td>3</td>\n",
       "      <td>0.057176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100963</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>MAR</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100964</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>MAY</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100965</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>NOV</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100966</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>OCT</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100967</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NL</td>\n",
       "      <td>SEP</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100968 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grouped_district  year          state state_symbol month  \\\n",
       "0              Agra, UP  2010  Uttar Pradesh           UP   APR   \n",
       "1              Agra, UP  2010  Uttar Pradesh           UP   AUG   \n",
       "2              Agra, UP  2010  Uttar Pradesh           UP   DEC   \n",
       "3              Agra, UP  2010  Uttar Pradesh           UP   FEB   \n",
       "4              Agra, UP  2010  Uttar Pradesh           UP   JAN   \n",
       "...                 ...   ...            ...          ...   ...   \n",
       "100963    Zunheboto, NL  2023       Nagaland           NL   MAR   \n",
       "100964    Zunheboto, NL  2023       Nagaland           NL   MAY   \n",
       "100965    Zunheboto, NL  2023       Nagaland           NL   NOV   \n",
       "100966    Zunheboto, NL  2023       Nagaland           NL   OCT   \n",
       "100967    Zunheboto, NL  2023       Nagaland           NL   SEP   \n",
       "\n",
       "        overall_count  ev_count  ev_share  \n",
       "0                2165         2  0.092379  \n",
       "1                4212         5  0.118708  \n",
       "2                4943         1  0.020231  \n",
       "3                3667         0  0.000000  \n",
       "4                5247         3  0.057176  \n",
       "...               ...       ...       ...  \n",
       "100963             66         0  0.000000  \n",
       "100964             83         0  0.000000  \n",
       "100965            116         0  0.000000  \n",
       "100966             86         0  0.000000  \n",
       "100967             54         0  0.000000  \n",
       "\n",
       "[100968 rows x 8 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registrations_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52c84133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>state</th>\n",
       "      <th>year_month</th>\n",
       "      <th>PRECTOTCORR</th>\n",
       "      <th>RH2M</th>\n",
       "      <th>T2M</th>\n",
       "      <th>T2MDEW</th>\n",
       "      <th>WS2M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.34</td>\n",
       "      <td>15.10</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>19.10</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.96</td>\n",
       "      <td>27.27</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.12</td>\n",
       "      <td>33.74</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>2010-05-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.39</td>\n",
       "      <td>37.19</td>\n",
       "      <td>6.08</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93751</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>6.23</td>\n",
       "      <td>82.38</td>\n",
       "      <td>24.82</td>\n",
       "      <td>21.16</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93752</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>7.40</td>\n",
       "      <td>84.57</td>\n",
       "      <td>23.69</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93753</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>6.44</td>\n",
       "      <td>81.52</td>\n",
       "      <td>20.98</td>\n",
       "      <td>17.31</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93754</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.72</td>\n",
       "      <td>16.85</td>\n",
       "      <td>11.51</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93755</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>0.47</td>\n",
       "      <td>77.26</td>\n",
       "      <td>13.80</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93756 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            district state year_month  PRECTOTCORR   RH2M    T2M  T2MDEW  WS2M\n",
       "0           Agra, UP    UP 2010-01-01         0.00  43.34  15.10    1.57  1.28\n",
       "1           Agra, UP    UP 2010-02-01         0.00  42.14  19.10    4.35  1.54\n",
       "2           Agra, UP    UP 2010-03-01         0.00  21.96  27.27    1.63  1.92\n",
       "3           Agra, UP    UP 2010-04-01         0.00  13.12  33.74    0.49  2.34\n",
       "4           Agra, UP    UP 2010-05-01         0.00  16.39  37.19    6.08  2.23\n",
       "...              ...   ...        ...          ...    ...    ...     ...   ...\n",
       "93751  Zunheboto, NL    NL 2022-08-01         6.23  82.38  24.82   21.16  0.18\n",
       "93752  Zunheboto, NL    NL 2022-09-01         7.40  84.57  23.69   20.60  0.22\n",
       "93753  Zunheboto, NL    NL 2022-10-01         6.44  81.52  20.98   17.31  0.29\n",
       "93754  Zunheboto, NL    NL 2022-11-01         0.00  72.72  16.85   11.51  0.42\n",
       "93755  Zunheboto, NL    NL 2022-12-01         0.47  77.26  13.80    9.50  0.43\n",
       "\n",
       "[93756 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a0e6a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>year_month</th>\n",
       "      <th>GWRPM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>79.480270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-05-01</td>\n",
       "      <td>77.330040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>60.452469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>56.436771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>49.920628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77008</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>16.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77009</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>19.314285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77010</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>16.542858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77011</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77012</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>12.171428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77013 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            district year_month    GWRPM25\n",
       "0           Agra, UP 2012-04-01  79.480270\n",
       "1           Agra, UP 2012-05-01  77.330040\n",
       "2           Agra, UP 2012-06-01  60.452469\n",
       "3           Agra, UP 2012-07-01  56.436771\n",
       "4           Agra, UP 2012-08-01  49.920628\n",
       "...              ...        ...        ...\n",
       "77008  Zunheboto, NL 2022-08-01  16.142857\n",
       "77009  Zunheboto, NL 2022-09-01  19.314285\n",
       "77010  Zunheboto, NL 2022-10-01  16.542858\n",
       "77011  Zunheboto, NL 2022-11-01   2.514286\n",
       "77012  Zunheboto, NL 2022-12-01  12.171428\n",
       "\n",
       "[77013 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_pm25_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "91dbd362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>year_month</th>\n",
       "      <th>nightlight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>11.859727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-05-01</td>\n",
       "      <td>5.769569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>7.382822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.066151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>2.599350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77008</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>0.624973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77009</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>0.639530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77010</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>0.579095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77011</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>0.622628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77012</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>0.682471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77013 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            district year_month  nightlight\n",
       "0           Agra, UP 2012-04-01   11.859727\n",
       "1           Agra, UP 2012-05-01    5.769569\n",
       "2           Agra, UP 2012-06-01    7.382822\n",
       "3           Agra, UP 2012-07-01    0.066151\n",
       "4           Agra, UP 2012-08-01    2.599350\n",
       "...              ...        ...         ...\n",
       "77008  Zunheboto, NL 2022-08-01    0.624973\n",
       "77009  Zunheboto, NL 2022-09-01    0.639530\n",
       "77010  Zunheboto, NL 2022-10-01    0.579095\n",
       "77011  Zunheboto, NL 2022-11-01    0.622628\n",
       "77012  Zunheboto, NL 2022-12-01    0.682471\n",
       "\n",
       "[77013 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_ntl_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ff97288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "registrations_dataset = registrations_dataset.rename(columns = {'grouped_district' : 'district'})\n",
    "registrations_dataset['month'] = registrations_dataset['month'].apply(lambda x: month_mapping[x])\n",
    "registrations_dataset['year_month'] = registrations_dataset['year'].astype(str) + '-' + registrations_dataset['month'].astype(str)\n",
    "registrations_dataset['year_month'] = pd.to_datetime(registrations_dataset['year_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "199bfe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataset = pd.merge(registrations_dataset, weather_dataset,\n",
    "                          on = ['district', 'year_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e7a9a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataset = pd.merge(master_dataset, urban_pm25_dataset,\n",
    "                          on = ['district', 'year_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "764e6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataset = pd.merge(master_dataset, urban_ntl_dataset,\n",
    "                          on = ['district', 'year_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "adde503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataset = master_dataset.drop(columns = ['state_x', 'state_y', 'year', 'month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e42047",
   "metadata": {},
   "source": [
    "# Section 7: Adding peer EV share column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5625f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "peers = {}\n",
    "for i in range(len(grouped_district_boundaries)):\n",
    "    district_peers = []\n",
    "    for j in range(len(grouped_district_boundaries)):\n",
    "        if grouped_district_boundaries['grouped_district'][j] != grouped_district_boundaries['grouped_district'][i]:\n",
    "            if grouped_district_boundaries['group_geometry'][j].touches(grouped_district_boundaries['group_geometry'][i]):\n",
    "                district_peers.append(grouped_district_boundaries['grouped_district'][j])\n",
    "            else:\n",
    "                pass\n",
    "        peers[grouped_district_boundaries['grouped_district'][i]] = district_peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3d9eeecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puducherry, PY\n",
      "Karaikal, PY\n",
      "Katihar, BR\n",
      "Kandhamal, OR\n",
      "South Andaman, AN\n",
      "Allahabad, UP\n"
     ]
    }
   ],
   "source": [
    "# LIST OF DISTRICTS NOT HAVING ANY TOUCHES\n",
    "for district in peers.keys():\n",
    "    if peers[district] == []:\n",
    "        print(district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4614a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataset['peer_evshare'] = np.nan\n",
    "for i in range(len(master_dataset)):\n",
    "    district = master_dataset['district'][i]\n",
    "    district_peers = peers[district]\n",
    "    narrowed_master_dataset = master_dataset[master_dataset['district'].isin(district_peers)]\n",
    "    \n",
    "    date = master_dataset['year_month'][i]\n",
    "    same_time = narrowed_master_dataset[narrowed_master_dataset['year_month'] == date].reset_index()\n",
    "    \n",
    "    if len(same_time) != 0:\n",
    "        peers_sum = same_time['ev_share'].sum()\n",
    "        n_peers = len(same_time)\n",
    "        master_dataset['peer_evshare'][i] = (peers_sum/n_peers)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "03ef521b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>state_symbol</th>\n",
       "      <th>overall_count</th>\n",
       "      <th>ev_count</th>\n",
       "      <th>ev_share</th>\n",
       "      <th>year_month</th>\n",
       "      <th>PRECTOTCORR</th>\n",
       "      <th>RH2M</th>\n",
       "      <th>T2M</th>\n",
       "      <th>T2MDEW</th>\n",
       "      <th>WS2M</th>\n",
       "      <th>GWRPM25</th>\n",
       "      <th>nightlight</th>\n",
       "      <th>peer_evshare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>6698</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014930</td>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.02</td>\n",
       "      <td>31.24</td>\n",
       "      <td>6.61</td>\n",
       "      <td>2.07</td>\n",
       "      <td>79.480270</td>\n",
       "      <td>11.859727</td>\n",
       "      <td>0.016709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>4804</td>\n",
       "      <td>3</td>\n",
       "      <td>0.062448</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>10.55</td>\n",
       "      <td>83.94</td>\n",
       "      <td>28.53</td>\n",
       "      <td>25.40</td>\n",
       "      <td>1.80</td>\n",
       "      <td>49.920628</td>\n",
       "      <td>2.599350</td>\n",
       "      <td>0.012860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>5100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.64</td>\n",
       "      <td>15.26</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.82</td>\n",
       "      <td>164.541702</td>\n",
       "      <td>11.842618</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>5019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.039849</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>5.27</td>\n",
       "      <td>60.72</td>\n",
       "      <td>32.82</td>\n",
       "      <td>23.11</td>\n",
       "      <td>2.41</td>\n",
       "      <td>56.436771</td>\n",
       "      <td>0.066151</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agra, UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>5560</td>\n",
       "      <td>5</td>\n",
       "      <td>0.089928</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.02</td>\n",
       "      <td>38.61</td>\n",
       "      <td>12.81</td>\n",
       "      <td>3.73</td>\n",
       "      <td>60.452469</td>\n",
       "      <td>7.382822</td>\n",
       "      <td>0.024313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77008</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>1.14</td>\n",
       "      <td>62.88</td>\n",
       "      <td>19.39</td>\n",
       "      <td>11.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.679109</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77009</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>8.83</td>\n",
       "      <td>78.12</td>\n",
       "      <td>22.59</td>\n",
       "      <td>18.04</td>\n",
       "      <td>0.28</td>\n",
       "      <td>20.414288</td>\n",
       "      <td>0.690581</td>\n",
       "      <td>0.012237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77010</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.72</td>\n",
       "      <td>16.85</td>\n",
       "      <td>11.51</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.514286</td>\n",
       "      <td>0.622628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77011</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>6.44</td>\n",
       "      <td>81.52</td>\n",
       "      <td>20.98</td>\n",
       "      <td>17.31</td>\n",
       "      <td>0.29</td>\n",
       "      <td>16.542858</td>\n",
       "      <td>0.579095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77012</th>\n",
       "      <td>Zunheboto, NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>7.40</td>\n",
       "      <td>84.57</td>\n",
       "      <td>23.69</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.22</td>\n",
       "      <td>19.314285</td>\n",
       "      <td>0.639530</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77013 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            district state_symbol  overall_count  ev_count  ev_share  \\\n",
       "0           Agra, UP           UP           6698         1  0.014930   \n",
       "1           Agra, UP           UP           4804         3  0.062448   \n",
       "2           Agra, UP           UP           5100         0  0.000000   \n",
       "3           Agra, UP           UP           5019         2  0.039849   \n",
       "4           Agra, UP           UP           5560         5  0.089928   \n",
       "...              ...          ...            ...       ...       ...   \n",
       "77008  Zunheboto, NL           NL             70         0  0.000000   \n",
       "77009  Zunheboto, NL           NL             58         0  0.000000   \n",
       "77010  Zunheboto, NL           NL             60         0  0.000000   \n",
       "77011  Zunheboto, NL           NL             56         0  0.000000   \n",
       "77012  Zunheboto, NL           NL             57         0  0.000000   \n",
       "\n",
       "      year_month  PRECTOTCORR   RH2M    T2M  T2MDEW  WS2M     GWRPM25  \\\n",
       "0     2012-04-01         0.00  24.02  31.24    6.61  2.07   79.480270   \n",
       "1     2012-08-01        10.55  83.94  28.53   25.40  1.80   49.920628   \n",
       "2     2012-12-01         0.00  41.64  15.26    1.24  1.82  164.541702   \n",
       "3     2012-07-01         5.27  60.72  32.82   23.11  2.41   56.436771   \n",
       "4     2012-06-01         0.00  23.02  38.61   12.81  3.73   60.452469   \n",
       "...          ...          ...    ...    ...     ...   ...         ...   \n",
       "77008 2022-03-01         1.14  62.88  19.39   11.22  0.45   43.000000   \n",
       "77009 2022-05-01         8.83  78.12  22.59   18.04  0.28   20.414288   \n",
       "77010 2022-11-01         0.00  72.72  16.85   11.51  0.42    2.514286   \n",
       "77011 2022-10-01         6.44  81.52  20.98   17.31  0.29   16.542858   \n",
       "77012 2022-09-01         7.40  84.57  23.69   20.60  0.22   19.314285   \n",
       "\n",
       "       nightlight  peer_evshare  \n",
       "0       11.859727      0.016709  \n",
       "1        2.599350      0.012860  \n",
       "2       11.842618      0.000000  \n",
       "3        0.066151      0.000000  \n",
       "4        7.382822      0.024313  \n",
       "...           ...           ...  \n",
       "77008    0.679109      0.000000  \n",
       "77009    0.690581      0.012237  \n",
       "77010    0.622628      0.000000  \n",
       "77011    0.579095      0.000000  \n",
       "77012    0.639530      0.000000  \n",
       "\n",
       "[77013 rows x 14 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6eedc2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataset.to_csv('Dataset for EV and pollution paper.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
